{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#idea-iconographical-definitional-epistemological-architecture","title":"IDEA: Iconographical Definitional Epistemological Architecture","text":"<p>A Graph Framework for Describing Visual Compositions and Modelling Uncertainty. Bridging the gap between flexible humanities research and high-performance data engineering.</p>"},{"location":"#repository-structure","title":"Repository Structure","text":"<pre><code>.\n\u251c\u2500\u2500 docs/                # Detailed technical specifications (Architecture etc.)\n\u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 00_core/         # The domain-agnostic engine (Cypher Statements, Fixtures)\n\u2502   \u251c\u2500\u2500 05_ontology/     # Multi-language support and semantic metadata (WIP)\n\u2502   \u2514\u2500\u2500 10_numismatics/  # Domain extension for ancient coinage (WIP)\n\u2514\u2500\u2500 README.md            # This file\n</code></pre>"},{"location":"#why-idea","title":"Why IDEA?","text":"<p>To investigate and search hundreds of thousands of coin datasets for our Imagines Nummorum project in real-time, we required a high-performance, scalable solution.</p> <p>While CIDOC CRM remains the academic gold standard for linked data in cultural heritage, implementing it at this specific scale and complexity often results in systems that are practically unusable for high-speed querying. Furthermore, we needed a native way to model scientific uncertainty and expert reasoning \u2014 areas where current standards offer no satisfactory high-performance solutions.</p> <p>IDEA is our tool, not our goal. It was born out of the necessity to achieve a comprehensive iconographical and semantic indexing of ancient Greek coinage. We invite the community to join us on this 25-year mission (2025\u20132050) and to adapt or evolve our architecture for their own research needs.</p>"},{"location":"#empowering-research-from-observation-to-insight","title":"Empowering Research: From Observation to Insight","text":"<p>IDEA is designed to act as a semantic workbench for scholars in numismatics, archaeology, and visual studies. It transforms static image descriptions into a dynamic, multidimensional knowledge graph.</p>"},{"location":"#what-can-researchers-do-with-idea","title":"What can researchers do with IDEA?","text":"<ul> <li>Complex Iconographical Queries: Perform advanced searches that go beyond simple keywords. You can query specific scene structures, such as: \"Show me all units where a deity (Entity) is holding (Relation) a weapon (Object)\".</li> <li>Modeling the \"Maybe\": In the humanities, truth is rarely binary. IDEA allows you to capture uncertainty by assigning certainty values (0.0\u20131.0) and documenting conflicting hypotheses or expert reasoning for every identification.</li> <li>Separating Sight from Meaning: Maintain a clean distinction between a neutral formal description (what is seen, the segment) and its epistemic interpretation (what it represents, the Platonic idea).</li> <li>Tracking Provenance &amp; Methodology: Every statement is linked to an Agent (Human/AI), ensuring that the history of an interpretation is fully traceable and bibliographically grounded. Source References and Methological information enable detailled reasoning.</li> <li>Flexible Ontological Mapping: The framework is architecturally agnostic. While it serves as the foundation for the upcoming ThING (Thesaurus Iconographicus Nummorum Graecorum), you can model and plug in any hierarchical classification system or domain-specific ontology to meet your research requirements.</li> <li>Quantifying Similarity: Utilize the Hub-and-Spoke model to identify and quantify \"diffuse\" similarities between compositions that are difficult to capture through traditional direct edges.</li> <li>Modular Extension Framework: IDEA is designed as a \"lean\", domain-agnostic core engine that can be easily extended to suit your specific research field. You can develop your own domain-specific modules or feature-rich extensions to add custom labels and properties without breaking the underlying four-layer logic.</li> </ul>"},{"location":"#technical-highlights","title":"Technical Highlights","text":"<p>IDEA is engineered for production-grade reasoning, moving beyond \"traditional\" academic graphs to a robust, scalable architecture.</p>"},{"location":"#1-epistemic-reification-solving-the-provenance-problem","title":"1. Epistemic Reification (Solving the Provenance Problem)","text":"<p>Instead of modelling facts as binary edges, IDEA reifies the act of interpretation as a first-class node (<code>Interpretation</code>):</p> <ul> <li>Atomic Accountability: Every semantic claim is a node, not a property on an edge, allowing for complex metadata (Certainty, Reasoning, Methodology) without \"Property-Graph-Bloat\".</li> <li>Provenance Tracking: Every semantic link carries metadata: <code>Agent</code> (Human/AI), <code>Methodology</code>, <code>Certainty</code> ( to ), and a <code>Reasoning Statement</code>.</li> <li>Deterministic RAG: Provides a high-fidelity roadmap for LLMs, mitigating hallucinations by forcing the model to traverse explicitly modeled uncertainty layers.</li> </ul>"},{"location":"#2-deterministic-query-depth-materialized-paths","title":"2. Deterministic Query Depth &amp; Materialized Paths","text":"<p>Standard graph models often suffer from unpredictable traversal costs due to deep ontological recursions. IDEA eliminates expensive <code>:IS_A*</code> lookups by materializing the hierarchy:</p> <ul> <li>O(1) Hierarchy Checks: Ancestral lookups in the concept tree are converted into simple array-membership checks using the <code>concept_path_ids</code> property.</li> <li>Path-Length Invariant: The distance from a physical <code>Unit</code> to its semantic <code>Concept</code> is structurally capped (e.g., 4 for Entities, 6 for Events).</li> <li>Performance Guarantee: By fixing traversal depth and materializing hierarchical paths, the model achieves near-constant O(1) vertical traversal complexity relative to the schema depth and O(log n) lookup efficiency, ensuring native compatibility with horizontally scalable graph engines.</li> </ul>"},{"location":"#3-linear-complexity-similarity-on-scaling","title":"3. Linear Complexity Similarity (O(n) Scaling)","text":"<p>To avoid the O(n\u00b2) \"dense graph\" trap where edges grow exponentially, IDEA utilizes a Centroid-based Hub-and-Spoke model:</p> <ul> <li>Topological Compression: Diffuse similarity is managed via <code>CompositionParallel</code> hubs rather than direct edges between compositions.</li> <li>Resource Efficiency: This reduces edge density by orders of magnitude, allowing the system to handle many compositions on commodity hardware without index collapse.</li> </ul>"},{"location":"#4-relational-single-source-of-truth-ssot","title":"4. Relational Single Source of Truth (SSoT)","text":"<p>IDEA is designed as a strict Read-Optimized Projection of a normalized relational database:</p> <ul> <li>Integrity-First: The graph layer acts as a high-performance materialized view, ensuring ACID compliance and formal data integrity at the source.</li> <li>Traceability: Every node carries a unique identifier (<code>_id</code>) mapped directly from the relational SSoT primary keys.</li> </ul>"},{"location":"#the-four-layer-architecture","title":"The Four-Layer Architecture","text":"<pre><code>graph LR\n    %% Nodes\n    A(Concrete)\n    B(Abstract)\n    C(Object Layer)\n    D(Formal Analysis Layer)\n    E(Epistemic Layer)\n    F(Ontological Layer)\n\n    %% Edges\n    A ----&gt; B\n    C --&gt; D    \n    D --&gt; E\n    E --&gt; F</code></pre> <p>The framework distinguishes between observation and interpretation through a strict four-layer logic:</p> Layer Focus Key Nodes I: Object Physical/Virtual Object/Carrier <code>Unit</code> II: Formal Analysis Structural Primitives (Neutral) <code>Composition</code>, <code>Entity</code>, <code>Relation</code> ... III: Epistemic Uncertainty &amp; Reasoning <code>Interpretation</code>, <code>Source</code>, <code>Agent</code>, <code>Comparison</code> IV: Ontological Abstract Concepts (ThING) <code>Concept</code>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To understand the core logic and explore the graph, we recommend the following paths:</p>"},{"location":"#1-essential-reading-theory-data","title":"1. Essential Reading (Theory &amp; Data)","text":"<p>Before diving into the code, please review these documents to understand the epistemic and structural foundations:</p> <ul> <li>Architecture Overview: Learn about the four-layer logic, epistemic reification, and the performance-centric design philosophy.</li> <li>Core Fixtures: Understand how abstract concepts are instantiated. This document includes references to visualizations of the example scenarios.</li> </ul>"},{"location":"#2-hands-on-running-the-sandbox","title":"2. Hands-on: Running the Sandbox","text":"<p>For a live demonstration of the IDEA framework, we provide a pre-configured Docker environment that automatically seeds the graph with our core logic and test data. Important Note: This Docker setup is intended for local demo and development purposes only. It is not hardened for production environments.</p> <ol> <li>Set up the Environment: if you need to change default password or ports, run <code>cp .env.example .env</code> and edit the related keys. </li> <li>Run the docker command: <code>docker-compose up</code> and wait for the seeding to be completed</li> <li>Access the Neo4j Browser: Open your browser and navigate to <code>http://localhost:7474</code> (User: noe4j, PW: password).</li> <li>The seeder has already loaded the constraints, indices, and fixtures from the <code>modules/00_core</code> directory.</li> <li>You can immediately run the examples from queries.md in the Neo4j Browser.</li> <li>Reset: use <code>docker-compose down -v</code> to revert any changes to the data</li> </ol> <p>If you want to build some datasets on you own, we recommand reading at least how-to-annotate-using-idea.md and nodes-and-edges.md.</p>"},{"location":"#author-governance","title":"Author &amp; Governance","text":"<p>IDEA is open-sourced software created and maintained by Jan K\u00f6ster and licensed under the Apache 2.0 license for the Academy Project \"Imagines Nummorum\" at the Berlin-Brandenburg Academy of Sciences and Humanities. This project  is part of the \"Akademienprogramm\", funded by German federal and state governments, which serves to preserve, secure and make present our cultural heritage. It is coordinated by the Union of German Academies of Sciences and Humanities.</p> <p>Contact: For any IDEA related topic we prefer direct communication on Github, for any contact to our initiative, see Contact</p>"},{"location":"#documentation-repository-access","title":"Documentation &amp; Repository Access","text":"<p>This project is optimized for an interactive documentation experience. </p> <ul> <li>Zenodo Users: For the full interactive experience, latest updates, and proper navigation, please switch to our GitHub Repository.</li> </ul>"},{"location":"#ai-transparency-methodology","title":"AI Transparency &amp; Methodology","text":"<p>In alignment with the epistemological focus of this project, transparency regarding the creation process is paramount. This graph model was developed with the assistance of Google Gemini (v2.5 Flash and 3 Pro), which served as an interactive dialogue partner and research tool.</p> <p>The AI's contribution included the following areas:</p> <ul> <li>Conceptual Brainstorming: Exploratory dialogue to refine the concept of the model.</li> <li>Best Practices Integration: Research and suggestions for adapting established patterns from graph theory and Neo4j.</li> <li>Coherence Validation: Reviewing and stress-testing the consistency of the terminology and structural logic used in the graph.</li> <li>Drafting Support: Generating initial outlines and structural sketches for the publication/documentation.</li> </ul> <p>Note on Authorship: While the AI provided support as described above, all final decisions, code implementations, and text formulations were curated, verified, and finalized by the maintainer mentioned above. The AI acted solely as an assistive tool, not as an autonomous agent/co-author.</p>"},{"location":"CONTRIBUTING/","title":"Contributing to IDEA","text":"<p>Thank you for your interest in the Iconographical Definitional Epistemological Architecture (IDEA). We welcome feedback and contributions that help refine this framework for the structured description of images and the modeling of uncertainty.</p>"},{"location":"CONTRIBUTING/#1-interaction-policy-issue-first","title":"1. Interaction Policy: Issue First","text":"<p>To ensure that all efforts are aligned with our long-term roadmap and architectural integrity, we follow a \"ticket-first\" workflow. Please open a GitHub Issue to discuss any proposed changes before submitting a Pull Request.</p>"},{"location":"CONTRIBUTING/#2-types-of-contributions","title":"2. Types of Contributions","text":"<p>We distinguish between different levels of contribution to maintain a focused project scope:</p>"},{"location":"CONTRIBUTING/#a-bugs-feedback-refinements","title":"A. Bugs, Feedback &amp; Refinements","text":"<p>We highly encourage reports on bugs or conceptual inconsistencies.</p> <ul> <li>Edge Case Suitability: We especially value feedback from users who test IDEA with their own datasets. Please report any \"edge cases\" where the current model reaches its limits.</li> </ul>"},{"location":"CONTRIBUTING/#b-core-enhancements","title":"B. Core Enhancements","text":"<p>Changes to 0-Modules like <code>00_core</code> or new core-level modules:</p> <ul> <li>Requirement: Must be in strict alignment with our core design principles (e.g., the four-layer logic) and the overall project goals.</li> </ul>"},{"location":"CONTRIBUTING/#c-domain-modules-within-scope-ancient-world","title":"C. Domain Modules: Within Scope (Ancient World)","text":"<p>If you wish to develop a module for a specific domain within our primary research scope (Numismatics, Archaeology, Ancient History):</p> <ul> <li>Policy: Please contact us first. These contributions are generally very welcome and may be integrated into the main repository after review.</li> </ul>"},{"location":"CONTRIBUTING/#d-domain-modules-outside-scope","title":"D. Domain Modules: Outside Scope","text":"<p>IDEA is designed to be versatile, but our resources are focused on the Ancient World.</p> <ul> <li>Policy: If you are developing a module for a different field (e.g., Modern Art, Biology, etc.), we recommend maintaining a separate repository.</li> <li>Integration: You should treat IDEA as a dependency. This keeps our core lean while allowing you full control over your domain-specific development. Remember: IDEA is our tool, not the goal of our project.</li> </ul>"},{"location":"CONTRIBUTING/#3-forking-adaptations-license","title":"3. Forking, Adaptations &amp; License","text":"<p>In accordance with the Apache License 2.0:</p> <ul> <li>Freedom to Adapt: We explicitly encourage you to fork, adapt, and transform IDEA for your own purposes.</li> <li>Attribution: Any derivative work must maintain proper attribution to the original IDEA repository and its authors.</li> <li>Notification: We are always happy to hear about how IDEA is being used or adapted, even if your project leaves our original scope.</li> </ul>"},{"location":"CONTRIBUTING/#4-academic-collaboration","title":"4. Academic Collaboration","text":"<p>If you are interested in a deeper research collaboration that goes beyond technical contributions to the graph framework:</p> <ul> <li>Contact: Please reach out to our Principal Investigators (PIs). Contact details can be found in on our Homepage.</li> </ul>"},{"location":"CONTRIBUTING/#5-architectural-integrity-the-golden-rule","title":"5. Architectural Integrity: The Golden Rule","text":"<p>Every contribution, especially when proposing new modules or refinements, must adhere to the IDEA Core Architecture:</p> <ul> <li>Immutable Four-Layer Logic: You may add specific node properties or specialized leaf-nodes, but you must never alter the fundamental four-layer structure (Object \u2192 Formal \u2192 Epistemic \u2192 Ontological).</li> <li>Directionality: Edges must always flow from the specific/concrete to the abstract/conceptual.</li> <li>Epistemic Transparency: No semantic link between a visual element in object context and a concept should exist without an intermediate <code>Interpretation</code> node.</li> </ul>"},{"location":"CONTRIBUTING/#6-style-and-conventions","title":"6. Style and Conventions","text":"<p>We recommand using the graph as an projection to keep a clear scheme. Consistency is key for a scalable graph. Please follow these naming conventions in all code contributions:</p> Element Convention Example Labels (Nodes) PascalCase <code>CompositionEntity</code>, <code>AIAgent</code> Properties lower_snake_case <code>reasoning_statement</code>, <code>certainty</code> Edges UPPER_SNAKE_CASE <code>IDENTIFIED_AS_CONCEPT</code> Uniqueness <code>_id</code> suffix <code>unit_id</code>, <code>concept_id</code>"},{"location":"known-issues/","title":"IDEA: Known Issues and Limitations","text":"<p>This document tracks identified architectural inconsistencies, simplified data representations in the fixtures, and planned structural refinements for future releases.</p>"},{"location":"known-issues/#1-non-exhaustive-fixture-annotation","title":"1. Non-Exhaustive Fixture Annotation","text":"<ul> <li>Description: The provided fixtures are for demonstration purposes only.</li> <li>Impact: They do not represent an exhaustive iconographical description of the objects. Many formal elements, features, or contexts that would be present in a production-level dataset are omitted to maintain focus on the Four-Layer Architecture.</li> </ul>"},{"location":"known-issues/#2-inconsistent-reading-lifecycle-the-billiard-ball-case","title":"2. Inconsistent Reading Lifecycle (The \"Billiard Ball\" Case)","text":"<ul> <li>Description: In the provided fixtures, a <code>Reading</code> proposed by an <code>AIAgent</code> is rejected by a <code>HumanAgent</code> without further action to the remaining data.</li> <li>Technical Debt: In a production environment, the rejection of a reading should trigger:</li> <li>The rejected <code>Reading</code> should be marked as <code>Rejected</code> (done).</li> <li>The remaining valid <code>Reading</code> needs to be set to <code>Outdated</code>, because the <code>certainty</code> changes, but a <code>Reading</code> cannot be changed (frozen in time)</li> <li> <p>A new \"Primary\" <code>Reading</code> should be generated with an updated (likely higher) <code>certainty</code> value replacing the outdated one.</p> </li> <li> <p>Reasoning: This step was omitted in the fixtures to simplify the visual representation of the graph in the Neo4j Browser for first-time users.</p> </li> </ul>"},{"location":"known-issues/#3-modeling-competing-interpretations","title":"3. Modeling Competing Interpretations","text":"<ul> <li>Description: While IDEA allows for multiple <code>Interpretation</code> nodes, the explicit relationship between competing hypotheses is currently handled only via the <code>status</code> property (\"Primary\", \"Alternative\", \"Rejected\" etc.).</li> <li>Planned Research: We are monitoring whether the current \"status-only\" approach is sufficient or if a dedicated edge type (e.g., <code>CONFLICTS_WITH</code>) is required to explicitly link mutually exclusive interpretations.</li> <li>Current Strategy: To avoid \"schema-less sprawl,\" we will observe this situation in controlled test cases before introducing new edge types to the IDEA Core.</li> </ul>"},{"location":"known-issues/#4-normalization-of-chromaticity","title":"4. Normalization of Chromaticity","text":"<ul> <li>Description: <code>Chromaticity</code> (e.g., polychromatic, monochromatic) is currently defined as a simple property of the <code>Composition</code> node.</li> <li>Refinement: Following graph normalization best practices, this attribute should likely be reified into its own node.</li> <li>Open Question: We are currently evaluating if chromaticity belongs within the CompositionContext layer or if it requires a dedicated node structure to better support queries regarding artistic techniques across different epochs.</li> </ul>"},{"location":"roadmap/","title":"IDEA: Roadmap 2026","text":"<p>This document outlines the development milestones for the IDEA framework in 2026. Following the initial release of the IDEA Core, which serves as a domain-agnostic engine for formal analysis, our focus shifts toward domain-specific extensions, the implementation of the relational Single Source of Truth (SSoT), and the development of internal tooling.</p>"},{"location":"roadmap/#phase-1-refining-the-core-domain-extensions-q1-2026","title":"Phase 1: Refining the Core &amp; Domain Extensions (Q1 2026)","text":"<p>The first quarter focuses on stabilizing the core architecture and expanding the framework into specific scientific domains.</p> <ul> <li>January: Community Review</li> <li>Open feedback loop and peer review phase following the initial GitHub release. Sie CONTRIBUTING.md</li> <li> <p>Refinement of the Four-Layer Architecture (Object, Formal Analysis, Epistemic, and Ontological).</p> </li> <li> <p>February: Module Expansion</p> </li> <li>Release: Ontology Module: Introducing human-readable labels and semantic definitions for the Ontology Layer, in our case the ThING (Thesaurus Iconographicus Nummorum Graecorum).</li> <li> <p>Release: Numismatics Module: Providing specialized labels and properties for coin-specific data, extending the IDEA Core without altering its fundamental logic.</p> </li> <li> <p>February/March: Scientific Communication</p> </li> <li> <p>Submission of the foundational paper on the IDEA framework to academic platforms.</p> </li> <li> <p>March: Relational SSoT Design</p> </li> <li>Drafting the SQL schema for the PostgreSQL backend.</li> <li>Establishing the 1:1 traceability between the graph projection and the relational SSoT primary keys using unique identifiers.</li> </ul>"},{"location":"roadmap/#phase-2-technical-implementation-tooling-q2-2026","title":"Phase 2: Technical Implementation &amp; Tooling (Q2 2026)","text":"<p>In the second quarter, IDEA transitions from a conceptual model into a functional data engineering environment.</p> <ul> <li>April: Infrastructure Deployment</li> <li>Setup of the IDEA test environment and API endpoints.</li> <li> <p>Implementation of the Schema-on-Write ETL process to ensure data remains strictly typed and verifiable.</p> </li> <li> <p>June: Internal Editor Prototype</p> </li> <li>Development of a Vue.js based Single Page Application (SPA).</li> <li>The editor will enforce the \"Golden Rule\" of modular design, ensuring extensions never alter core edge directionality.</li> </ul>"},{"location":"roadmap/#future-outlook-public-engagement-late-2026-beyond","title":"Future Outlook: Public Engagement (Late 2026 &amp; Beyond)","text":"<ul> <li>Prototype: ThING Public Portal</li> <li>Development of a public-facing website with graph-based search capabilities.</li> <li>Implementation of performance-optimized design patterns, such as materialized hierarchy paths, to ensure  or  performance for complex ancestral lookups.</li> </ul> <p>Note on Capacity: IDEA is an academic research project driven by a small, dedicated team with limited personnel resources. Please be aware that even short-term absences or unforeseen events can lead to significant delays in this roadmap. We prioritize intellectual honesty and data integrity over rapid implementation.</p>"},{"location":"docs/00_conceptual-framework/","title":"Conceptual Framework","text":""},{"location":"docs/00_conceptual-framework/#1-idea-as-a-research-catalyst","title":"1. IDEA as a Research Catalyst","text":"<p>IDEA (Iconographical Definitional Epistemological Architecture) is the structural scaffolding for a larger scientific mission. Our primary goal is the development and dissemination of the ThING (Thesaurus Iconographicus Nummorum Graecorum) \u2014 a multidimensional, hierarchical ontology designed to categorize the vast visual heritage of the ancient world. To build, refine, and provide the ThING as a high-performance research tool, we require a framework capable of handling hundreds of thousands of datasets over a 25-year period (2025\u20132050).</p>"},{"location":"docs/00_conceptual-framework/#2-beyond-the-cidoc-crm-bottleneck","title":"2. Beyond the CIDOC CRM Bottleneck","text":"<p>While CIDOC CRM is the gold standard for cultural heritage documentation, its abstraction often results in a \"performance tax\" when dealing with mass data.</p> <ul> <li>The Complexity Challenge: Modeling hundreds of thousands of scenes with highly nested event-based structures makes real-time graph traversals and rapid data entry difficult for large-scale projects.</li> <li>The IDEA Alternative: We developed IDEA as a specialized tool for Large-Scale Iconography. By using a fixed-depth architecture and a strict projection from a relational SSoT (Single Source of Truth), we achieve the performance necessary for advanced queries while maintaining semantic precision.</li> </ul>"},{"location":"docs/00_conceptual-framework/#3-the-performance-rigor-trade-off","title":"3. The Performance-Rigor Trade-off","text":"<p>Ancient numismatics and archaeology operate at the intersection of mass data and individual expert interpretation. IDEA bridges this gap:</p> <ul> <li>Efficiency: The framework is optimized for a workflow where experts validate generated drafts (LLM-supported) rather than building every node from scratch.</li> <li>Interdisciplinary Modularization: IDEA is built on the principle of Open Science and Reciprocity. By strictly separating a domain-agnostic Core from specialized extensions, we facilitate the reuse of our framework across different disciplines. We invite other fields to adapt the concept for their specific needs while benefiting from IDEA\u2019s logic for handling uncertainty and formal analysis.</li> </ul>"},{"location":"docs/00_conceptual-framework/#4-the-epistemic-mandate-modeling-uncertainty","title":"4. The Epistemic Mandate: Modeling Uncertainty","text":"<p>The greatest challenge in digitizing historical images is the \"illusion of certainty.\" Traditional databases often force a binary choice: either an object is, or it is not.</p> <ul> <li>Honest Data: IDEA treats uncertainty as a structural feature. Through the Epistemic Layer, we reify interpretation, allowing \"maybe\" to be as searchable as \"is\".</li> <li>Quantification: By assigning <code>certainty</code> values and linking them to reasoning statements and methodologies (<code>Architectonic</code>), we create a \"transparent graph\". This allows researchers to query for \"all certain identifications\" as easily as for \"all controversial hypotheses.\"</li> </ul>"},{"location":"docs/00_conceptual-framework/#5-vision-a-high-resolution-dataset-for-the-future","title":"5. Vision: A High-Resolution Dataset for the Future","text":"<p>By documenting not just the results, but the process of interpretation, IDEA is able to generate unique \"extremity datasets\". This architecture is designed to provide future AI training models with a nuanced understanding of ambiguity and evidence \u2014 the same tools human scholars use to navigate the past.</p>"},{"location":"docs/00_conceptual-framework/#6-the-cold-start-challenge-call-for-collaboration","title":"6. The \"Cold Start\" Challenge &amp; Call for Collaboration","text":"<p>We are currently in the infrastructure-building phase. While the IDEA framework and the input interfaces are reaching maturity, the primary challenge remains the scale of data ingestion. * The Bottleneck: Manually annotating hundreds of thousands of ancient coins with the depth required by IDEA is not feasible through human labor alone. * AI Pipelines: We are developing complex AI-driven pipelines to migrate and structure legacy data from our predecessor project, Corpus Nummorum and other sources. These pipelines utilize IDEA's <code>pattern</code> feature to generate initial structures that can be reused both, by AI and human to build the detailled datasets. * Open Invitation: We invite experts in Natural Language Processing (NLP) and Computer Vision / Image Analysis to collaborate with us. The complexity of ancient iconography provides a unique playground for testing and refining next-generation information extraction models.</p>"},{"location":"docs/01_architecture/","title":"IDEA: Architectural Overview","text":""},{"location":"docs/01_architecture/#1-design-philosophy","title":"1. Design Philosophy","text":"<p>The development of IDEA is designed to bridge the gap between flexible humanities research and high-performance data engineering:</p> <ul> <li>Epistemic Primacy (Modeling the \"Maybe\"): Unlike traditional models that force reality into binary 1s and 0s, IDEA treats interpretation as a first-class citizen. By reifying the interpretive act into its own node, we allow for the structured representation of uncertainty, conflicting hypotheses, and expert reasoning. Diffuse similarity between objects is modeled via centroid-structures (Hub-and-Spoke) rather than direct edges, enabling nuanced similarity quantification.</li> <li>Relational-to-Graph Integrity: IDEA is designed as a strict Read-Optimized Projection of a relational database (Single Source of Truth, e.g., PostgreSQL). Every node, edge, and property in the graph must have a schematic counterpart in the relational model. This prevents \"schema-less sprawl\" and ensures that the data remains verifiable, migratable, and strictly typed. In production we will operate on a strict \"Schema-on-Write\" principle during the ETL process.</li> <li>Horizontal Scalability &amp; Performance-Centric Flatness: The graph is engineered to grow in \"width\" (number of units) rather than \"depth\" (traversal length). To reach O(1) or O(log n) performance for complex queries, the depth from a physical unit to an ontological concept is fixed (typically 4 to 6 hops). Deep ontological recursions are bypassed by materializing hierarchy paths directly as node properties. See performance-and-scaling.md</li> <li>Modular Framework Design: The framework distinguishes between the IDEA Core \u2014 a lean, domain-agnostic engine for formal analysis \u2014, Core Extensions (e.g., for ontology management) and specialized Domain Extensions (e.g., <code>IDEA Numismatics</code>). Our \"Golden Rule\" states: Modules may extend the Core with specialized labels or properties, but they must never alter the fundamental four-layer logic or the core edge directionality (from concrete to abstract).</li> <li>Multi-Modal Readiness: While the current implementation focuses on static visual media (coins, stelae, paintings), the underlying logic of distinguishing between objects, formal elements, epistemic interpretations and concepts is intentionally medium-agnostic. The concept is prepared for future expansions into moving images, complex 3D objects, or textual analysis.</li> </ul>"},{"location":"docs/01_architecture/#2-style-and-conventions","title":"2. Style and Conventions","text":"Element Convention Example Labels (Nodes) PascalCase <code>CompositionEntity</code>, <code>AIAgent</code> Properties lower_snake_case <code>reasoning_statement</code>, <code>certainty</code> Edges UPPER_SNAKE_CASE <code>IDENTIFIED_AS_CONCEPT</code> Uniqueness <code>_id</code> suffix <code>unit_id</code>, <code>concept_id</code> <p>ID Strategy: Every node carries a unique identifier (<code>_id</code>) mapped directly from the relational SSoT primary keys. This ensures 1:1 traceability between the graph projection and the SQL source. Please note: the fixtures are populated with string-based identifiers for easier navigation in the Neo4j Browser.</p>"},{"location":"docs/01_architecture/#3-the-atomic-core-elements","title":"3. The Atomic Core Elements","text":"<p>To maintain semantic precision across all layers, IDEA utilizes seven core categories. These categories are used to define visual elements, abstract patterns, and ontological concepts:</p> <ul> <li>Entity: Any discrete being or object.</li> <li>Feature: Attributes, states belonging to an Entity.</li> <li>Relation: Directed atomic actions or relationships between two Entities.</li> <li>Modifier: Specific details describing the execution of a Relation (e.g., handedness).</li> <li>Event: Macro-level actions composed of multiple atomic Relations.</li> <li>Context: References to external frameworks like mythology, history, or publication contexts.</li> <li>Group: Logical containers or spatial regions (e.g., a text block or a logical arrangement). (no Concept)</li> </ul>"},{"location":"docs/01_architecture/#4-the-four-layer-architecture","title":"4. The Four-Layer Architecture","text":"<p>The Four-Layer Architecture is the backbone of the IDEA Core</p>"},{"location":"docs/01_architecture/#layer-i-object-layer","title":"Layer I: Object Layer","text":"<p>Represents the physical or virtual object (e.g., a specific coin) which has one or more <code>Composition</code> (Layer II).</p> <pre><code>flowchart TD\n    %% Classes \n    classDef unit fill:#194d33,stroke:none,color:#eee; \n    classDef composition fill:#9f0500,stroke:none,color:#eee;\n\n    %% Nodes\n    A(Unit):::unit\n    B(Composition A):::composition\n    C(Composition B):::composition\n\n    %% Edges\n    A -- HAS_COMPOSITION --&gt; B\n    A -- HAS_COMPOSITION --&gt; C</code></pre> <ul> <li>Nodes: <code>Unit</code>.</li> </ul>"},{"location":"docs/01_architecture/#layer-ii-formal-analysis-layer-description","title":"Layer II: Formal Analysis Layer (Description)","text":"<p>A structural decomposition of the image in functional primitives.</p> <pre><code>flowchart TD\n    %% Classes \n    classDef composition fill:#9f0500,stroke:none,color:#eee;\n    classDef element fill:#c45100,stroke:none,color:#eee;\n    classDef group fill:#fe9200,stroke:none,color:#eee;\n\n    %% Nodes\n    A(Composition):::composition\n    B(CompositionEntity A):::element \n    C(CompositionEntity B):::element\n    D(CompositionFeature):::element\n    E(CompositionRelation):::element\n    F(CompositionModifier):::element\n    G(CompositionEvent):::element\n    H(CompositionContext):::element\n    I(CompositionGroup):::group\n\n    %% Edges\n    A -- HAS_COMPOSITION_ENTITY --&gt; B\n    A -- HAS_COMPOSITION_ENTITY --&gt; C\n    B -- HAS_COMPOSITION_FEATURE --&gt; D\n    B -- HAS_COMPOSITION_RELATION --&gt; E\n    E -- HAS_COMPOSITION_OBJECT --&gt; C\n    B ~~~ C\n    E -- HAS_COMPOSITION_MODIFIER --&gt; F\n    E -- HAS_COMPOSITION_EVENT --&gt; G\n    A -- HAS_COMPOSITION_CONTEXT --&gt; H\n    A -- HAS_COMPOSITION_GROUP --&gt; I</code></pre> <ul> <li>Nodes: <code>Composition</code>, <code>CompositionEntity</code>, <code>CompositionFeature</code>, <code>CompositionRelation</code>, <code>CompositionModifier</code>, <code>CompositionEvent</code>, <code>CompositionGroup</code>, <code>CompositionContext</code>.</li> <li>Logic: Captures what is seen without assigning final meaning.</li> </ul>"},{"location":"docs/01_architecture/#layer-iii-epistemic-layer","title":"Layer III: Epistemic Layer","text":""},{"location":"docs/01_architecture/#a-interpretation-uncertainty-and-reasoning","title":"A) Interpretation / Uncertainty and Reasoning","text":"<p>The core of IDEA\u2019s uncertainty modeling. No semantic link exists without an intermediate interpretation node.</p> <pre><code>flowchart TD\n    %% Classes \n    classDef element fill:#c45100,stroke:none,color:#eee;\n    classDef interpretation fill:#ab149e,stroke:none,color:#eee;\n    classDef concept fill:#0062b1,stroke:none,color:#eee;\n    classDef agent fill:#653294,stroke:none,color:#eee;\n    classDef sourceRef fill:#16a5a5,stroke:none,color:#eee;\n    classDef source fill:#194d33,stroke:none,color:#eee;\n    classDef architectonic fill:#4C8EDA,stroke:none,color:#eee;\n\n    %% Nodes\n    A(Element):::element\n    B(Interpretation):::interpretation \n    C(Concept):::concept\n    D(Agent):::agent\n    E(Methodology UncertaintySource):::architectonic\n    F(Methodology Evidence):::architectonic\n    G(Methodology SourceRelation):::architectonic\n    H(SourceReference):::sourceRef\n    I(Source):::source\n\n    %% Edges\n    A -- HAS_INTERPRETATION --&gt; B\n    B -- IDENTIFIED_AS_CONCEPT --&gt; C\n    B -- STATED_BY --&gt; D\n    B -- IMPAIRED_BY --&gt; E\n    B -- SUPPORTED_BY --&gt; F\n    B -- HAS_SOURCE_REFERENCE --&gt; H\n    H -- HAS_EVIDENTIARY_RELATIONSHIP --&gt; G\n    H -- HAS_SOURCE --&gt; I</code></pre> <ul> <li>Nodes: <code>Interpretation</code>, <code>Reading</code>, <code>SourceReference</code>, <code>Source</code>, <code>Agent</code>, <code>Architectonic</code>.</li> <li>Uncertainty: Stores <code>certainty</code> values (float) and expert reasoning.</li> <li>Provenance: <code>Agent</code> nodes identify the author (Human/AI), while <code>Source</code> and <code>SourceReference</code> provide bibliographic evidence.</li> <li>Methodology: <code>Architectonic</code> nodes define the meta-ontology of the interpretation (e.g., \"Logical Deduction\" or \"Ambiguity\").</li> </ul>"},{"location":"docs/01_architecture/#b-similarity","title":"B) Similarity","text":"<p>To model \"diffuse\" similarity between images without creating direct edges, IDEA uses a Hub-and-Spoke model. \u201cDiffuse\u201d refers to similarities that are difficult or impossible to model in the structure of the graph because the concepts involved are too far apart.</p> <pre><code>flowchart TD\n    %% Classes \u00b4\n    classDef composition fill:#9f0500,stroke:none,color:#eee;\n    classDef comparison fill:#ab149e,stroke:none,color:#eee;\n    classDef agent fill:#653294,stroke:none,color:#eee;\n    classDef parallel fill:#009ce0,stroke:none,color:#eee;\n    classDef architectonic fill:#4C8EDA,stroke:none,color:#eee;\n\n    %% Nodes\n    A(Composition A):::composition\n    B(Composition B):::composition\n    C(Comparison A):::comparison\n    D(Comparison B):::comparison\n    E(Agent):::agent\n    F(CompositionParallel):::parallel\n    G(Methodology ParallelType):::architectonic\n\n    %% Edges\n    A -- HAS_COMPARISON --&gt; C\n    B -- HAS_COMPARISON --&gt; D\n    C -- STATED_BY --&gt; E\n    D -- STATED_BY --&gt; E\n    C -- ASSERTED --&gt; F\n    D -- ASSERTED --&gt; F\n    F -- HAS_PARALLEL_TYPE --&gt; G</code></pre> <ul> <li>Hub: <code>CompositionParallel</code>.</li> <li>Mechanism: Multiple <code>CompositionComparison</code> nodes point to a single <code>Parallel</code> hub with aggregated properties (assertion count, similarity average and deviation).</li> <li>Benefit: Reduces edge density significantly while allowing complex similarity quantification.</li> </ul>"},{"location":"docs/01_architecture/#layer-iv-ontological-layer","title":"Layer IV: Ontological Layer","text":""},{"location":"docs/01_architecture/#a-concepts","title":"A) Concepts","text":"<p>Defines the abstract world of concepts.</p> <pre><code>flowchart TD\n    %% Classes \n    classDef concept fill:#0062b1,stroke:none,color:#eee;\n\n    %% Nodes\n    A(Concept):::concept\n    B(Concept):::concept\n    C(Concept):::concept\n    D(Concept):::concept\n    E(Concept):::concept\n\n    %% Edges\n    A -- IS_A --&gt; D\n    B -- IS_A --&gt; D\n    C -- IS_A --&gt; D\n    D -- IS_A --&gt; E</code></pre> <ul> <li>Nodes: <code>Concept</code>, <code>Pattern</code>, <code>PatternEntity</code>, <code>PatternRelation</code>.</li> <li>Concepts: An abstract hierarchy of lemmas (Entity, Relation, etc.) used for classification. </li> <li>Core Limitation: To maintain domain-agnosticism and high performance, the IDEA Core treats Concepts as structural anchors with minimal properties (primarily <code>concept_id</code>).</li> <li>Extension - Module 05_ontology: For human-readable labels, multi-language support, and detailed definitions, the Core is extended by the Ontology Module. This module handles the semantic \"flesh\" of the ThING, allowing the Core to remain a lean navigational skeleton (Work in Progress).</li> </ul>"},{"location":"docs/01_architecture/#b-patterns","title":"B) Patterns","text":"<p>Patterns Act as Presets and Filters. They provide an iconographical blueprint (e.g., \"Human holding object\") to quickly find all Compositions matching a specific scene structure without diving into detailed analysis. They work like a reduced Layer II. They are linked via an Interpretation node directly to the compositions. Within the pattern description there are no interpretation nodes since they are already operating on the abstract, \"idle\" level of Concepts.</p>"},{"location":"docs/01_architecture/#5-high-performance-design-patterns","title":"5. High-Performance Design Patterns","text":""},{"location":"docs/01_architecture/#linear-scaling-fixed-traversals","title":"Linear Scaling &amp; Fixed Traversals","text":"<p>The model is optimized for very large datasets (hundreds of thousands of compositions).</p> <ul> <li>Width over Depth: Adding new compositions increases the \"width\" of the graph. The \"depth\" (hops from Unit to Concept) remains constant.</li> <li>O(1) Hierarchy Checks: Using materialized path arrays (<code>concept_path_ids</code>), ancestral lookups in the concept tree are converted into simple array-membership checks. see performance-and-scaling.md.</li> <li>To find a Unit with a specific Entity/Context: Unit -&gt; Composition -&gt; CompositionEntity/CompositionContext -&gt; Interpretation -&gt; Concept (4 Hops)</li> <li>To find a Unit with a specific Feature/Relation: Unit -&gt; Composition -&gt; CompositionEntity -&gt; CompositionFeature/CompositionRelation -&gt; Interpretation -&gt; Concept (5 Hops)</li> <li>To find a Unit with a specific Modifier/Event: Unit -&gt; Composition -&gt; CompositionEntity -&gt; CompositionRelation -&gt; CompositionModifier/CompositionEvent -&gt; Interpretation -&gt; Concept (6 Hops)</li> </ul>"},{"location":"docs/02_performance-and-scaling/","title":"IDEA: Performance and Scaling","text":"<p>[!IMPORTANT] Architectural Status: The infrastructure described in this document\u2014specifically the Postgres-as-Single-Source-of-Truth (SSoT) and the automated ETL Pipeline \u2014 is currently a conceptual design. It serves as a roadmap for implementation and is not yet part of the active codebase.</p>"},{"location":"docs/02_performance-and-scaling/#1-core-objectives","title":"1. Core Objectives","text":"<p>The IDEA graph model employs a deep layered architecture to preserve epistemic nuance. While this is ideal for data integrity, it introduces high \"hop-counts\" for standard queries. This strategy defines how we denormalize specific paths during the transfer from the relational SSoT to the Graph DB to achieve:</p> <ul> <li>O(1) Hierarchy Lookups: Bypassing recursive traversals in the Tree of Concepts.</li> <li>Low-Latency Standard Views: Providing direct access to high-certainty data for front-end consumers.</li> <li>Reduced Computational Overhead: Shifting complex logic from query-time to ingest-time.</li> </ul>"},{"location":"docs/02_performance-and-scaling/#2-hierarchical-flattening-materialized-paths","title":"2. Hierarchical Flattening (Materialized Paths)","text":"<p>To avoid expensive recursive <code>:IS_A</code> traversals within the <code>Concept</code> hierarchy, we will implement Materialized Path Arrays.</p>"},{"location":"docs/02_performance-and-scaling/#implementation-concept_path_ids","title":"Implementation: <code>concept_path_ids</code>","text":"<p>Each <code>Concept</code> node will be enriched with a property containing its entire ancestral lineage.</p> <ul> <li>Property: <code>concept_path_ids</code> (Type: <code>LIST&lt;STRING&gt;</code> or <code>LIST&lt;INT&gt;</code>).</li> <li>Content: An ordered array starting from the root concept down to the node's own ID (e.g., <code>[\"root-id\", \"parent-id\", \"self-id\"]</code>).</li> <li>Technical Benefit: Enables high-performance filtering using Neo4j's array indexing.</li> <li>Query Example: <code>MATCH (n:Concept) WHERE 'target-concept-id' IN n.concept_path_ids</code> instead of <code>MATCH (n:Concept)-[:IS_A*]-&gt;(t:Concept {concept_id: 'target-concept-id'})</code>.</li> </ul>"},{"location":"docs/02_performance-and-scaling/#3-the-epistemic-bypass-shortcut-relations","title":"3. The Epistemic Bypass (Shortcut Relations)","text":"<p>The Epistemic Layer uses <code>Interpretation</code> nodes to model uncertainty. For the majority of end-user queries, we can bypass this layer when the data meets specific \"Gold Standard\" criteria.</p>"},{"location":"docs/02_performance-and-scaling/#31-entity-to-concept-shortcut","title":"3.1 Entity-to-Concept Shortcut","text":"<p>We collapse the path from a formal element to its semantic identification.</p> <ul> <li>Source Node: <code>CompositionEntity</code>.</li> <li>Target Node: <code>Concept</code>.</li> <li>Relationship: <code>HAS_CERTAIN_PRIMARY_CONCEPT</code>.</li> <li>Materialization Trigger:</li> <li><code>Interpretation.status == \"Primary\"</code>.</li> <li><code>Interpretation.certainty &gt;= 0.8</code> (Current threshold).</li> </ul>"},{"location":"docs/02_performance-and-scaling/#32-composition-to-reading-shortcut","title":"3.2 Composition-to-Reading Shortcut","text":"<p>We bypass layout-based grouping nodes (e.g., <code>CompositionGroup</code>) to allow direct text-based filtering on the composition level.</p> <ul> <li>Source Node: <code>Composition</code>.</li> <li>Target Node: <code>Reading</code>.</li> <li>Relationship: <code>HAS_CERTAIN_PRIMARY_READING</code>.</li> <li>Materialization Trigger:</li> <li><code>Reading.status == \"Primary\"</code>.</li> <li><code>Reading.certainty &gt;= 0.8</code> (Current threshold).</li> </ul>"},{"location":"docs/02_performance-and-scaling/#4-proposed-etl-workflow-conceptual","title":"4. Proposed ETL Workflow (Conceptual)","text":"<p>The materialization logic resides entirely within the ETL (Extract, Transform, Load) pipeline.</p> Step Action Description 1. Extract Daily Snapshot Pull latest state from Postgres SSoT. 2. Transform Path Calculation Compute the <code>concept_path_ids</code> array using a recursive CTE in Postgres. 3. Transform Shortcut Logic Evaluate <code>status</code> and <code>certainty</code> thresholds to determine shortcut eligibility. 4. Load Graph Rebuild Wipe the Neo4j instance (or specific labels) and perform a high-speed <code>UNWIND</code> load. Use Blue-Green Deployment to avoid downtime"},{"location":"docs/02_performance-and-scaling/#5-performance-monitoring","title":"5. Performance Monitoring","text":"<p>Post-materialization, the following indices must be maintained in Neo4j to ensure the effectiveness of this strategy:</p> <ul> <li>Lookup Index: On <code>Concept(concept_path_ids)</code>.</li> <li>Constraint: Unique IDs for all materialized relationships to prevent duplication during incremental updates (if implemented).</li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/","title":"How to Annotate with IDEA","text":"<p>This guide walks you through the process of describing a visual scene using the IDEA framework. To illustrate the workflow, we will use the \"Apple-Tomato\" example: a composition where a human hand holds a red object that could be either an apple or a tomato.</p> <p>Instead of just \"tagging\" an image, we build a path from the concrete observation to the abstract concept, documenting every step of the interpretive process.</p> <p>We recommand having the following files at hand: * architecture.md * nodes-and-edges.md * fixtures.md</p>"},{"location":"docs/03_how-to-annotate-using-idea/#the-workflow-vertical-stacking","title":"The Workflow: Vertical Stacking","text":"<p>For every element you identify, you complete the path from Layer II (Formal) to Layer IV (Ontological) before moving to the next element.</p> <p>Note on Methodology: While CV models typically use a horizontal stack approach (processing all entities, then all features, then all relations across the entire composition to maximize computational efficiency), we recommend the vertical stack approach for human annotators. This is often more accessible to the human mind as it maintains the semantic context of a single visual element \u2014 from observation to interpretation \u2014 before moving to the next part of the image.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#step-0-define-the-frame-layer-i-ii","title":"Step 0: Define the Frame (Layer I &amp; II)","text":"<p>Before describing content, establish the <code>Unit</code> and the visual container (<code>Composition</code>).</p> <p>Note on Units: When dealing only with virtual resources, the unit may seem redundant at first glance, but it is indispensable when handling real-world objects such as, in our case, ancient coins, as we have a physical carrier and multiple image zones (compositions).</p> <ul> <li>Unit: The physical/virtual object (e.g., <code>unit-apple-tomato</code>).</li> <li>Composition: The specific view or side being analyzed (e.g., <code>composition-apple-tomato</code>).</li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#step-1-identify-an-entity-the-apple-tomato","title":"Step 1: Identify an Entity (The \"Apple-Tomato\")","text":"<p>Now, we describe the red object held in the hand.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#11-the-formal-observation-layer-ii","title":"1.1 The Formal Observation (Layer II)","text":"<p>Create a <code>CompositionEntity</code>. At this stage, do not think of it as an \"apple\"; it is simply a \"thing\" in the image.</p> <ul> <li>Node: <code>(entity-at-apple-tomato:CompositionEntity)</code></li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#12-the-interpretive-act-layer-iii","title":"1.2 The Interpretive Act (Layer III)","text":"<p>This is the \"Epistemic Primary\" step. Since the object is ambiguous, we create two interpretations for the same entity.</p> <ul> <li>Interpretation A: Likely a tomato.</li> <li><code>certainty: 0.5</code>, <code>reasoning_statement: \"Tomato texture, uncommon shape\"</code> </li> <li>Interpretation B: Possibly an apple.</li> <li><code>certainty: 0.4</code>, <code>reasoning_statement: \"Apple shape, but no stem\"</code> </li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#13-linking-to-concepts-layer-iv","title":"1.3 Linking to Concepts (Layer IV)","text":"<p>Connect each interpretation to the global <code>Concept</code> tree (ThING).</p> <ul> <li><code>Interpretation A</code> --IDENTIFIED_AS_CONCEPT--&gt; <code>concept-tomato</code> </li> <li><code>Interpretation B</code> --IDENTIFIED_AS_CONCEPT--&gt; <code>concept-apple</code> </li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#step-2-describe-features","title":"Step 2: Describe Features","text":"<p>Entities have attributes. Let's describe the color of our object.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#21-formal-feature-layer-ii","title":"2.1 Formal Feature (Layer II)","text":"<ul> <li>Node: <code>(feature-at-apple-color:CompositionFeature)</code></li> <li>Edge: <code>entity-at-apple-tomato</code> --HAS_COMPOSITION_FEATURE--&gt; <code>feature-at-apple-color</code></li> </ul> <p>Feature vs. Relation: Features are Attributes/states of an entity. While <code>standing</code> is a state, <code>standing_on</code> is directed and requires an object (another entity). <code>standing_on</code> should therefore be modeled as a <code>Relation</code>. In many cases it es a good idea to model both (<code>standing</code> as <code>Feature</code> and <code>standing_</code> as <code>Relation</code>) since it makes queries easier.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#22-interpretation-concept-layer-iii-iv","title":"2.2 Interpretation &amp; Concept (Layer III &amp; IV)","text":"<ul> <li>Interpretation: Certainty 1.0 (it is definitely red).</li> <li>Concept: <code>concept-red</code> </li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#step-3-map-relations-and-actions","title":"Step 3: Map Relations and Actions","text":"<p>An image is rarely static. In our example, a human is holding the object.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#31-the-relation-layer-ii","title":"3.1 The Relation (Layer II)","text":"<p>Define the action between the human (<code>entity-at-human</code>) and the object.</p> <ul> <li>Node: <code>(relation-at-holding:CompositionRelation)</code></li> <li>Edges:</li> <li><code>entity-at-human</code> --HAS_COMPOSITION_RELATION--&gt; <code>relation-at-holding</code> </li> <li><code>relation-at-holding</code> --HAS_COMPOSITION_RELATION_OBJECT--&gt; <code>entity-at-apple-tomato</code> </li> </ul> <p>Relation vs. Event: A Relation is the atomic link between two distinct entities. For relations between 3 or more entities, use <code>Event</code> nodes: <code>Relation</code> --HAS_COMPOSITION_EVENT--&gt; <code>Event</code></p>"},{"location":"docs/03_how-to-annotate-using-idea/#32-adding-modifiers","title":"3.2 Adding Modifiers","text":"<p>Was it the right or left hand?</p> <ul> <li>Modifier: <code>modifier-at-using-right-hand</code> </li> <li>Interpretation: \"Arrangement of fingers indicates the right hand.\" </li> <li>Concept: <code>concept-using-right-hand</code> </li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#step-4-handling-the-hand-and-cropping-visual-scope","title":"Step 4: Handling \"The Hand\" and Cropping (Visual Scope)","text":"<p>A common pitfall is to declare the hand as its own <code>Entity</code>. In IDEA, we usually treat the Human as the entity, while the Hand and the fact that it is a Detail (cropped) are handled as <code>Features</code>.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#41-why-not-entity-hand","title":"4.1 Why not \"Entity: Hand\"?","text":"<p>If we labeled the hand as an entity, we would lose the connection to the person. Instead, we identify the person as the entity and describe the \"hand-ness\" and the \"cropping\" as attributes of how that person is depicted.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#42-formal-feature-visual-scope-layer-ii","title":"4.2 Formal Feature: Visual Scope (Layer II)","text":"<p>We observe that only a part of the human is visible.</p> <ul> <li>Node: <code>(feature-at-human-visual-scope:CompositionFeature)</code> </li> <li>Edge: <code>entity-at-human</code> --HAS_COMPOSITION_FEATURE--&gt; <code>feature-at-human-visual-scope</code> </li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#43-interpretation-the-cropping-layer-iii","title":"4.3 Interpretation: The Cropping (Layer III)","text":"<p>We document why we think this is a detail.</p> <ul> <li>Interpretation: <code>interpretation-at-human-visual-scope</code> </li> <li>Reasoning: \"Obvious cropping of the subject at the right edge of the frame.\" </li> <li>Certainty: <code>1.0</code> (it is a factual observation of the frame) </li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#44-ontological-mapping-visual-scope-layer-iv","title":"4.4 Ontological Mapping: Visual Scope (Layer IV)","text":"<p>Finally, we link this to the ThING to enable queries like \"Show me all human details\".</p> <ul> <li>Primary Concept: <code>concept-detail-hand</code> </li> <li>Parent Concept: <code>concept-human-visual-scope</code>  (which is a type of <code>concept-visual-scope</code>) </li> </ul> <p>Feature vs. Entity: If it is a part of a larger being (like a hand, an eye, or a wing), model it as a Feature of that being. If it is a separate, moveable object (like a sword, a shield, or a tomato), model it as a separate Entity.</p>"},{"location":"docs/03_how-to-annotate-using-idea/#step-5-justify-with-methodology-architectonics","title":"Step 5: Justify with Methodology (Architectonics)","text":"<p>To make your uncertainty transparent, link your interpretations to methodological \"Architectonics.\"</p> <ul> <li>Conflict: If a reference image shows a stem but yours doesn't, use <code>architectonic-conflicting</code>. </li> <li>Ambiguity: If the shape is unclear, mark the interpretation as --<code>IMPAIRED_BY</code>--&gt; <code>architectonic-ambiguity</code>. </li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#step-6-abstract-meanings-compositioncontext","title":"Step 6: Abstract Meanings (CompositionContext)","text":"<p>Sometimes, a composition refers to something that isn't a physical \"thing\" in the image, such as a historical event, a specific myth, or a publication context.</p> <ul> <li>The Problem: You cannot point to a \"Battle of Actium\" node in the visual pixels, but the image is clearly about it.</li> <li>The Solution: Use a <code>CompositionContext</code> node.</li> <li>Workflow:</li> <li>Formal: Create a <code>CompositionContext</code> and link it to your <code>Composition</code>.</li> <li>Epistemic: Add an <code>Interpretation</code> (e.g., certainty 1.0, reasoning: \"Defined by publication context\").</li> <li>Ontological: Link to the abstract concept (e.g., <code>concept-functional-demo</code> or a historical event concept).</li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#step-7-dealing-with-text-reading-groups","title":"Step 7: Dealing with Text (Reading &amp; Groups)","text":"<p>To handle text (like the \"7\" on a billiard ball), IDEA uses a specific structure that separates the logical container from the actual signs.</p> <ol> <li>Create a Container: Create a <code>CompositionGroup</code> with the <code>group_function: \"TextContainer\"</code> and link it to the <code>Composition</code>.</li> <li>Optional Glyphs: If you want to be precise, create <code>CompositionEntity</code> nodes for individual letters/signs and link them to the group using <code>IS_PART_OF_COMPOSITION_GROUP</code>.</li> <li>The Reading: Instead of a standard <code>Interpretation</code>, link a <code>Reading</code> node to the <code>CompositionGroup</code>.</li> <li>Properties: In addition to <code>certainty</code>, a <code>Reading</code> includes <code>read_string</code> (the transcribed text) and <code>lang</code> (the language, e.g., \"EN\").</li> <li>Logic: Just like interpretations, readings can be <code>STATED_BY</code> an agent or <code>IMPAIRED_BY</code> ambiguity (e.g., due to wear on a coin).</li> </ol>"},{"location":"docs/03_how-to-annotate-using-idea/#summary-of-the-path","title":"Summary of the Path","text":"<p>When you are finished, a single \"observation\" (the red object) looks like this in the graph:</p> <p><code>Composition</code> \u2192 <code>CompositionEntity</code> \u2192 <code>Interpretation</code> \u2192 <code>Concept</code></p> <p>Note: This path might seem longer than a simple tag, but it allows IDEA to answer complex questions like: \"Show me all objects where the identification as 'Apple' was disputed due to 'Ambiguity'.\"</p>"},{"location":"docs/03_how-to-annotate-using-idea/#important-why-no-graphical-annotations-polygons","title":"Important: Why no Graphical Annotations (Polygons)?","text":"<p>You might notice that there are no properties for coordinates or polygons (e.g., SVG/JSON) in the graph nodes. This is a deliberate design choice for performance and efficiency.</p> <ul> <li>Separation of Concerns: IDEA follows a strict \"Read-Optimized Projection\" philosophy.</li> <li>Spatial Performance: Complex spatial queries (e.g., \"Is entity A inside the region of group B?\") are handled much more efficiently in a relational database like PostgreSQL using spatial extensions.</li> <li>The Link: We will store the graphical coordinates (polygons) in the relational Single Source of Truth (SSoT). These are mapped to the unique <code>_id</code> of the <code>CompositionEntity</code> or <code>CompositionGroup</code>.</li> <li>The Result: The graph stays lean and fast for semantic traversals, while the frontend fetches the visual coordinates from the SQL backend when it needs to draw them on the screen.</li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#additional-structures","title":"Additional Structures:","text":""},{"location":"docs/03_how-to-annotate-using-idea/#using-patterns-as-blueprints","title":"Using Patterns as Blueprints","text":"<p>When a scene follows a common iconographical scheme (e.g., \"Human holding an object\"), you don't have to reinvent the wheel every time. IDEA uses Patterns as reusable blueprints.</p> <ul> <li>Simplified Structure: Unlike a full analysis, a <code>Pattern</code> uses a reduced set of nodes: only <code>PatternEntity</code> and <code>PatternRelation</code>.</li> <li>No Epistemic Layer inside Patterns: Because patterns are abstract and \"idle,\" they don't need interpretation nodes or certainty values within their own structure; they link directly to <code>Concepts</code>.</li> <li>Linking to Reality: To apply a pattern to a real image, you create an <code>Interpretation</code> node between the <code>Composition</code> (or <code>CompositionPattern</code>) and the <code>Pattern</code>.</li> <li>Benefit: This \"epistemic shift\" makes patterns much faster to create and act as a filter for thousands of similar images.</li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#patterns-as-a-scaffold-for-ai-annotation","title":"Patterns as a \"Scaffold\" for AI Annotation","text":"<p>Patterns serve a critical role in automated workflows, especially when dealing with ambiguous or damaged material where a specific scene cannot be identified with certainty.</p> <ul> <li>Contextual Grounding: Even if an AI agent cannot recognize a specific mythological or historical scene, a Pattern provides the necessary structural scaffold.</li> <li>Iconographical \"Priors\": Patterns act as visual archetypes (e.g., \"Enthroned figure with scepter\"). If the AI identifies a \"Figure\" and a \"Scepter,\" the Pattern suggests the most probable relational structure, even if the specific identity of the deity remains unknown.</li> <li>Error Reduction: By forcing the AI to align its findings with predefined <code>PatternEntity</code> and <code>PatternRelation</code> structures, we reduce the risk of \"hallucinated\" relations that do not exist in the iconographical record. Of cause we have to be careful with so far unknown scenes.</li> <li>Human-in-the-Loop: The AI proposes a <code>PatternRecognition</code> based on these blueprints, which a human expert can then easily validate or refine by setting the <code>certainty</code> value in the Interpretation layer.</li> </ul>"},{"location":"docs/03_how-to-annotate-using-idea/#modeling-similarity-the-centroid-approach","title":"Modeling Similarity (The Centroid Approach)","text":"<p>If two or more compositions look alike, IDEA avoids creating direct \"looks-like\" edges between every single image. Instead, we use a Centroid Model to handle clusters of similarity.</p> <ol> <li>The Hub: A <code>CompositionParallel</code> node acts as the center (centroid) of a similarity cluster.</li> <li>The Spokes: Each <code>Composition</code> is linked to this hub via a <code>CompositionComparison</code> node.</li> <li>Aggregated Data: The hub stores the collective data of the cluster, such as the <code>similarity_average</code> and the <code>assertion_count</code>.</li> <li>Connecting Clusters: For images that are only slightly similar, we do not create a new huge cluster. Instead, we create a single \"bridge\" between two representative compositions of different clusters.</li> <li>Human vs. AI: While humans often prefer 1:1 comparisons, this centroid approach is specifically designed for AI agents. AI can efficiently calculate these clusters based on feature vectors, making the graph a perfect training set for machine learning.</li> </ol>"},{"location":"docs/04_ai-annotation-pipeline/","title":"IDEA: AI-Assisted Annotation Pipeline (Blueprint)","text":""},{"location":"docs/04_ai-annotation-pipeline/#1-executive-summary-breaking-the-cold-start-problem","title":"1. Executive Summary: Breaking the \"Cold Start\" Problem","text":"<p>The manual annotation of hundreds of thousands of cultural heritage objects using the IDEA Four-Layer Architecture is a high-precision but resource-intensive task. To achieve critical mass data, we need an AI-assisted pipeline.</p> <p>This pipeline is designed to solve the Cold Start Problem: transforming legacy text-based descriptions into structured graph data. By utilizing Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG), we shift the expert's role from data entry to data validation (Human-in-the-loop).</p> <p>Note: This pipeline is currently a conceptual blueprint and is in the early stages of implementation.</p>"},{"location":"docs/04_ai-annotation-pipeline/#2-pipeline-architecture","title":"2. Pipeline Architecture","text":""},{"location":"docs/04_ai-annotation-pipeline/#phase-1-ontological-grounding-thing-integration","title":"Phase 1: Ontological Grounding (ThING Integration)","text":"<p>The pipeline is anchored in the existing Ontological Layer (Layer IV).</p> <ul> <li>Input: The matured ThING vocabulary, consisting of hierarchical concepts (as of now &gt;1k distinct entities).</li> <li>Process: The LLM is provided with the project's onotology to ensure semantic precision.</li> <li>Mechanism: Semantic Anchoring ensures that the AI does not \"guess\" but maps identified entities directly to existing <code>concept_id</code> values.</li> <li>Output: A system-prompt-ready taxonomy that prevents \"semantic drift\" or the creation of redundant tags.</li> </ul>"},{"location":"docs/04_ai-annotation-pipeline/#phase-2-pattern-distillation-mass-processing","title":"Phase 2: Pattern Distillation (Mass Processing)","text":"<p>Before annotating individual units, we define the iconographical \"vocabulary\" using legacy data.</p> <ul> <li>Input: Legacy descriptions and metadata.</li> <li>Process: * NER &amp; Relation Extraction: LLMs extract entities and actions from text.</li> <li>Abstraction: Identifying recurring motifs to create Pattern nodes.</li> <li>Output: A robust graph populated with \"blueprints\" of common scenes.</li> </ul>"},{"location":"docs/04_ai-annotation-pipeline/#phase-3-composition-drafting-automated-mapping","title":"Phase 3: Composition Drafting (Automated Mapping)","text":"<p>Using the distilled patterns, the system generates initial graph drafts for new objects.</p> <ul> <li>Input: Single-unit descriptions and metadata.</li> <li>Process: * Pattern Matching: The LLM identifies which existing <code>Pattern</code> matches the description.</li> <li>Layer II Generation: The system automatically instantiates <code>CompositionElement</code> nodes based on the matched pattern.</li> <li>Output: A \"Silver Standard\" graph without finalized certainty values.</li> </ul>"},{"location":"docs/04_ai-annotation-pipeline/#phase-4-expert-in-the-loop-epistemic-enrichment","title":"Phase 4: Expert-in-the-Loop (Epistemic Enrichment)","text":"<p>The crucial step where \"data\" becomes \"scholarly knowledge.\"</p> <ul> <li>Process: Experts review the AI-generated drafts via the future IDEA Web Frontend.</li> <li>Action:</li> <li>Validate or reject the <code>Interpretation</code> Nodes (no deletion to get feedback for the AI).</li> <li>create new <code>Interpretation</code> nodes and link Methodology/Sources for complex interpretations.</li> <li>Output: The Gold Standard dataset.</li> </ul>"},{"location":"docs/04_ai-annotation-pipeline/#phase-5-scaling-via-rag-vector-db","title":"Phase 5: Scaling via RAG &amp; Vector DB","text":"<p>As the Gold Standard grows, the system becomes self-improving.</p> <ul> <li>Process: </li> <li>Validated [Text Description + Cypher Statement] pairs are stored in a Vector Database.</li> <li>For new, un-annotated units, the system performs a similarity search.</li> <li>The LLM uses the most similar \"Gold\" examples as context (Few-Shot RAG) to generate high-quality Cypher drafts.</li> <li>Impact: Drastic reduction in manual correction time over the project's lifespan.</li> </ul>"},{"location":"docs/04_ai-annotation-pipeline/#3-technical-stack","title":"3. Technical Stack","text":"Component Technology Role LLM Orchestration LangChain / LangGraph Managing multi-step extraction and validation loops. Vector Database Milvus / Weaviate Storing embeddings of legacy descriptions and Cypher snippets. Graph DB Neo4j The queryable projection of the IDEA model. Single Source of Truth PostgreSQL Relational storage for all validated transactions. Validation UI Vue.js Expert interface for the Human-in-the-loop phase."},{"location":"docs/04_ai-annotation-pipeline/#4-why-this-approach","title":"4. Why this Approach?","text":"<ol> <li>Hallucination Control: Grounding the LLM in Phase 1 (ThING) and Phase 2 (Patterns) prevents the AI from \"inventing\" iconographical concepts outside the defined ontology.</li> <li>Epistemic Transparency: The AI proposes, but the human signs off on the <code>certainty</code>. The graph preserves the provenance via <code>Agent</code> nodes.</li> <li>Efficiency: Moving from Generation to Verification increases annotation speed by an estimated factor of 5 to 10.</li> <li>Legacy Data Valorization: It turns decades of unstructured text-based research into a machine-readable training set for future models.</li> </ol>"},{"location":"docs/04_ai-annotation-pipeline/#5-future-outlook-from-text-to-graph-to-image-to-graph","title":"5. Future Outlook: From Text-to-Graph to Image-to-Graph","text":"<p>While the current pipeline focuses on Natural Language Processing (NLP) to leverage existing legacy descriptions, the IDEA architecture is inherently medium-agnostic. The long-term objective is a hybrid analysis model or a direct Computer Vision (CV) approach:</p> <ul> <li>Direct Image Annotation: Future iterations will utilize AI models to perform instance segmentation directly on coin images, identifying and labeling segments as <code>CompositionEntity</code> nodes.</li> <li>Hybrid Multimodal Analysis: By combining visual segment analysis with free-text descriptions, the system can cross-validate findings, further increasing the <code>certainty</code> of interpretations in the Epistemic Layer.</li> <li>Training Data Acquisition: We are currently seeking resources to segment a large-scale corpus of numismatic imagery. This will create the necessary ground-truth dataset to train custom models capable of recognizing highly stylized or worn ancient iconography.</li> </ul>"},{"location":"docs/05_trustworthy-ai/","title":"IDEA's Epistemic Layer Pattern: A Blueprint for Trustworthy AI","text":""},{"location":"docs/05_trustworthy-ai/#1-beyond-domain-specificity-the-meta-architecture","title":"1. Beyond Domain Specificity: The Meta-Architecture","text":"<p>While the IDEA framework was originally developed for iconographical research, its core innovation lies in the decoupling of domain-specific data from epistemic evaluation. IDEA's Layer III addresses the \"Hallucination of Certainty\" in LLMs by moving interpretation from an implicit process into an explicit graph node. This separation allows for a universal thought pattern that can be applied to any field requiring high-stakes decision-making and uncertainty modeling. IDEA's Layer III provides the structural \"glass box\" for reasoning, uncertainty, and provenance that remains constant across disciplines.</p>"},{"location":"docs/05_trustworthy-ai/#2-the-core-mechanism","title":"2. The Core Mechanism","text":"<p>Instead of direct mapping, every link must pass through an Interpretation Node. This reification allows an AI or a human expert to:</p> <ol> <li>Attach Uncertainty: Assign a <code>certainty</code> value (float) to any claim.</li> <li>Model Methodology: Use <code>Architectonic</code> nodes to define how a conclusion was reached (e.g., \"Empirical Observation\" vs. \"LLM Inference\").</li> <li>Trace Agency: Link every statement to an <code>Agent</code> (AI/Human) and a <code>Source</code>, ensuring accountability in agentic workflows.</li> </ol>"},{"location":"docs/05_trustworthy-ai/#3-the-agentic-workflow-specialized-expert-agents","title":"3. The Agentic Workflow: Specialized Expert Agents","text":"<p>Applying the Layer III mechanics enables a shift from general-purpose \"Chatbots\" to Agentic Expert Ensembles.</p>"},{"location":"docs/05_trustworthy-ai/#step-1-orchestration-threshold-detection","title":"Step 1: Orchestration &amp; Threshold Detection","text":"<p>A high-level LLM (the Orchestrator) receives a user prompt. If requested by the user or if the prompt involves a high-stakes decision (e.g., \"Verify this historical hypothesis\" or \"Assess risk in this dataset\"), the Orchestrator does not answer directly. It triggers specialized Expert Agents.</p>"},{"location":"docs/05_trustworthy-ai/#step-2-the-expert-agent-the-thinker","title":"Step 2: The Expert Agent (The \"Thinker\")","text":"<p>These are \"pruned\" LLMs\u2014models with high reasoning capabilities but minimal \"world knowledge\" to prevent internal hallucinations.</p> <ul> <li>Schema Awareness: The Expert Agent is trained on the graph schema (since this graph is a projection of a relational SSoT the schema is strict and easy to apply).</li> <li>Graph Interaction: It generates precise Cypher queries to explore the Graph.</li> <li>Methodological Rigor: It evaluates the Architectonic nodes to see how an interpretation was reached (e.g., \"Was this a logical deduction or an automated classification?\").</li> </ul>"},{"location":"docs/05_trustworthy-ai/#step-3-the-expert-report","title":"Step 3: The Expert Report","text":"<p>The agent produces a grounded report, an Numismatic Expert Agent might answer like this:</p> <p>\"Based on the IDEA Graph, there are three competing interpretations due to ambiguity for this scene. Interpretation A has a certainty of 0.8 (supported by Source X), while Interpretation B is a minority view (certainty 0.3) but is supported by a more recent publication. Moreover, there is an interesserting compositional parallel to another coin from Thrace which implies an interpretation as Y with a certainty of 0.6.\"</p>"},{"location":"docs/05_trustworthy-ai/#step-4-transparent-synthesis","title":"Step 4: Transparent Synthesis","text":"<p>The Orchestrator presents the user with the full spectrum of expert findings (it makes totally sense to use more than one expert Agent on the same problem at once). Important: The Orchestrator must preserves the plurality of thought. A short overview or abstract on the experts reports might be useful, but the reports must be presented in full.</p>"},{"location":"docs/05_trustworthy-ai/#summary-a-new-paradigm-for-ai-interaction","title":"Summary: A New Paradigm for AI Interaction","text":"<p>By adopting IDEA's Layer III mechanics, we move from Stochastic Generation (guessing the next word) to Structural Analysis (navigating a graph of weighted interpretations). This pattern allows AI systems to participate in scientific discourse by respecting the \"Maybe\" and providing a verifiable audit trail for every conclusion.</p>"},{"location":"docs/05_trustworthy-ai/#4-breaking-the-crystalline-intelligence","title":"4. Breaking the \"Crystalline\" Intelligence","text":"<p>Traditionally, an AI's knowledge is \"frozen\" after training. This setup allows for Active Knowledge Shaping:</p> <ul> <li>Dynamic Updating: Agents can be authorized to write back to the graph, creating new nodes or updating existing ones as new data arrives.</li> <li>Self-Correction: If an AI identifies a logical contradiction between two parts of the graph, it can flag these for human review, turning the database into a living, self-auditing organism.</li> <li>Avoid the Risk: Of cause it needs a robust mechanism to ensure that an agent cannot break it's own graph. Since the graph should be a projection, any Write on the SSoT should be handled like a merge request which must be carefully evaluated.</li> </ul>"},{"location":"docs/05_trustworthy-ai/#5-performance","title":"5. Performance","text":"<p>The \"pruned\" Agent Models are much smaller and require less resources. On the other hand the graph must be super performant. IDEA addresses this problem by growing in width, not in depth, by applying its similarity-centroid-solution and its performance optimizations. </p>"},{"location":"docs/05_trustworthy-ai/#6-project-scope-and-future-outlook","title":"6. Project Scope and Future Outlook","text":""},{"location":"docs/05_trustworthy-ai/#disclaimer-and-visionary-responsibility","title":"Disclaimer and Visionary Responsibility","text":"<p>The comprehensive implementation of the agentic backbone described above significantly transcends our research goals and financial resources. Nevertheless, we view it as our responsibility to present these structural potentials for broader discussion, especially since our own numismatic research workflows would gain substantial analytical rigor from such a specialized expert agent. While we provide the epistemic blueprint through Layer III, the large-scale technical realization of these autonomous reasoning systems remains a task for the wider AI research and engineering community.</p>"},{"location":"docs/05_trustworthy-ai/#risk-assessment-and-intellectual-agency","title":"Risk Assessment and Intellectual Agency","text":"<p>The practical realization of this architecture is not a technocratic \"fix\" for uncertainty; it demands a rigorous risk assessment and the intellectual agency of the inquirer. IDEA is designed as an instrument for critical scientific discourse, not as a \"truth machine\" that replaces human judgment.</p> <p>To avoid a naive reliance on automated systems, every implementation must ensure that: * Human Responsibility remains Central: The final synthesis of complex, uncertain data cannot be offloaded to an algorithm without the constant vigilance of an informed human mind. * Critical Evaluation is Mandatory: Users are placed under the obligation to actively weigh the conflicting hypotheses and certainty scores provided by the Expert Agents. * Integrity is Protected: Robust mechanisms (such as the suggested \"Merge Request\" approach for SSoT writes) must prevent agents from undermining the structural foundation of the knowledge base.</p> <p>Ultimately, the power of IDEA lies not in providing final answers, but in empowering the user to make informed, responsible decisions amidst the inherent ambiguity of human knowledge.</p>"},{"location":"docs/99_glossary/","title":"Glossary","text":"<p>This glossary provides shared definitions to bridge the gap between numismatic research and graph data engineering.</p>"},{"location":"docs/99_glossary/#1-domain-specific-terms-numismatics-iconography","title":"1. Domain-Specific Terms (Numismatics &amp; Iconography)","text":"<ul> <li>Imagines Nummorum: Our research intiative at the Berlin-Brandenburg Academy of Sciences and Humanities</li> <li>Corpus Nummorum: Our previous research intiative, which we are still actively maintaining</li> <li>ThING (Thesaurus Iconographicus Nummorum Graecorum): The central, multidimensional ontology (Tree of Concepts) that serves as the semantic backbone for our studies.</li> </ul>"},{"location":"docs/99_glossary/#2-technical-terms","title":"2. Technical Terms","text":"<ul> <li>SSoT (Single Source of Truth): The primary relational database (PostgreSQL) where all data is strictly validated and stored before being projected into the graph.</li> <li>Reification: The process of turning an abstract relationship (like an interpretation) into a physical node in the graph to allow for properties like <code>certainty</code> and <code>reasoning_statement</code>.</li> <li>Hub-and-Spoke (Centroid Model): A design pattern where a central node (the Hub) connects multiple entities to avoid a quadratic explosion of direct relationships (Spokes).</li> <li>Materialized Path: A performance optimization where the entire lineage of a concept is stored as an array (<code>concept_path_ids</code>) on the node itself to avoid recursive queries.</li> </ul>"},{"location":"docs/99_glossary/#3-architecture","title":"3. Architecture","text":"<ul> <li>Unit: The physical or virtual object acting as the information carrier (e.g., a specific ancient coin).</li> <li>Composition: A visual container representing a specific side or area of a Unit, housing all formal elements identified during analysis.</li> <li>Pattern: An abstract iconographical blueprint or \"preset\" used to identify recurring scene structures across different Compositions.</li> <li>Entity: Any discrete being or object (concrete or abstract).</li> <li>Feature: Attributes, states, or typographic properties belonging to an Entity.</li> <li>Relation: Directed atomic actions or relationships between two Entities.</li> <li>Modifier: Specific details describing the execution of a Relation (e.g., handedness).</li> <li>Event: Macro-level actions composed of multiple atomic Relations.</li> <li>Context: References to external frameworks like mythology, history, or publication contexts.</li> <li>Group: Logical containers or spatial regions (e.g., a text block or a logical arrangement). (no Concept)</li> </ul>"},{"location":"docs/99_glossary/#4-epistemic-terms","title":"4. Epistemic Terms","text":"<ul> <li>Certainty: A floating-point value (0.0 to 1.0) representing the level of confidence an Agent has in a specific interpretation.</li> <li>Interpretation Node: The mandatory intermediary node between a formal element and its semantic concept, used to model the \"epistemic act\" of identification.</li> <li>Architectonic: Meta-concepts used to describe the methodology or the source of uncertainty (e.g., \"damaged surface\" or \"stylistic comparison\").</li> </ul>"},{"location":"modules/00_core/","title":"IDEA Core","text":"<p>This module contains the formal technical specification and reference implementation of the IDEA Core. It defines the fundamental structure required to describe units, compositions, and epistemic interpretations.</p>"},{"location":"modules/00_core/#quick-links","title":"Quick Links","text":"<ul> <li>Architecture: For the theoretical foundation, see <code>architecture.md</code>.</li> <li>Scaling: Learn about our O(1) traversal strategy in <code>performance-and-scaling.md</code>.</li> </ul>"},{"location":"modules/00_core/#technical-specifications","title":"Technical Specifications","text":"<ul> <li><code>nodes-and-edges.md</code>: Definition of all Core labels, properties, and relationships.</li> <li><code>data-dictionary.md</code>: Allowed values for Enums (e.g., status, chromaticity).</li> <li><code>fixtures.md</code>: Documentation of the provided test datasets.</li> <li><code>queries.md</code>: Example Cypher queries for common analytical tasks.</li> </ul>"},{"location":"modules/00_core/#deployment","title":"Deployment","text":"<p>To initialize a Neo4j instance with the IDEA Core, execute the Cypher scripts in the following order (or let the seeder in our docker-compose.yml do its job): 1. <code>00_constraints.cypher</code>: Enforces uniqueness and required properties. 2. <code>01_index.cypher</code>: Optimizes lookup performance. 3. <code>99_fixtures.cypher</code>: Ingests the sample graph data described in <code>fixtures.md</code>.</p> <p>Note: As per the Golden Rule of Extension, any other module must build upon this Core without altering its four-layer logic.</p>"},{"location":"modules/00_core/data-dictionary/","title":"IDEA Core: Data Dictionary","text":"<p>This document defines the allowed values, data types, and constraints for properties within the IDEA Core. It ensures data integrity across the Relational Database (Source of Truth) and the Graph DB (Query Layer).</p>"},{"location":"modules/00_core/data-dictionary/#1-global-value-constraints","title":"1. Global Value Constraints","text":"<p>These constraints apply to all nodes and edges where these property names are used.</p> Property Type Range / Format Description <code>certainty</code> FLOAT Confidence level of an interpretation or reading. <code>timestamp</code> STRING ISO 8601 (YYYY-MM-DD) Date of creation or validation. <code>lang</code> STRING ISO 639-1 / 639-3 Language code (e.g., \"EN\", \"LAT\", \"GRC\")."},{"location":"modules/00_core/data-dictionary/#2-core-enumerations-enums","title":"2. Core Enumerations (ENUMs)","text":"<p>The following values are the current defaults for the IDEA Core. These lists are non-exhaustive and will be expanded by future updates.</p>"},{"location":"modules/00_core/data-dictionary/#21-composition-enums","title":"2.1 Composition Enums","text":""},{"location":"modules/00_core/data-dictionary/#chromaticity","title":"<code>chromaticity</code>","text":"<p>Used in the <code>Composition</code> node to describe visual color properties.</p> <ul> <li><code>Polychromatic</code>: Multi-colored appearance.</li> <li><code>Monochromatic</code>: Single color or grayscale appearance.</li> </ul> <p>Note: We consider using a separate node instead of a property</p>"},{"location":"modules/00_core/data-dictionary/#22-structural-enums","title":"2.2 Structural Enums","text":""},{"location":"modules/00_core/data-dictionary/#group_function","title":"<code>group_function</code>","text":"<p>Used in <code>CompositionGroup</code> to define the logical or spatial purpose of a container.</p> <ul> <li><code>LogicalUnit</code>: A functional grouping of entities.</li> <li><code>TextContainer</code>: A region specifically designated for inscriptions or signs.</li> </ul>"},{"location":"modules/00_core/data-dictionary/#23-epistemic-enums","title":"2.3 Epistemic Enums","text":""},{"location":"modules/00_core/data-dictionary/#status","title":"<code>status</code>","text":"<p>Used in <code>Interpretation</code> and <code>Reading</code> to define the weight of a statement.</p> <ul> <li><code>Primary</code>: The currently favored or most widely accepted interpretation.</li> <li><code>Alternative</code>: A valid but secondary interpretation.</li> <li><code>Rejected</code>: An interpretation that has been explicitly dismissed by an agent.</li> </ul>"},{"location":"modules/00_core/data-dictionary/#scope","title":"<code>scope</code>","text":"<p>Used in the <code>IDENTIFIED_AS_CONCEPT</code> and <code>HAS_CONCEPT</code> edges. It qualifies the nature of the link between a formal element and a semantic concept. The <code>scope</code> poperty is set if the cardinality is  N &gt; 1.</p> <ul> <li><code>VisualAppearance</code>: Relates to what the element looks like.</li> <li><code>ActualMeaning</code>: Relates to the specific identification.</li> <li><code>FunctionalMeaning</code>: Relates to the role within the scene.</li> </ul>"},{"location":"modules/00_core/data-dictionary/#3-ontological-structures","title":"3. Ontological Structures","text":"<p>IDEA uses two distinct hierarchical systems (Strictly Acyclic Graphs).</p>"},{"location":"modules/00_core/data-dictionary/#31-concept-taxonomy-thing","title":"3.1 Concept Taxonomy (ThING)","text":"<ul> <li>Labels: <code>Concept</code> (Sub-labels: <code>Entity</code>, <code>Feature</code>, <code>Relation</code>, <code>Modifier</code>, <code>Event</code>, <code>Context</code>).</li> <li>Property: <code>concept_id</code> (INT, Unique).</li> <li>Hierarchy: Defined by <code>IS_A</code> edges.</li> </ul>"},{"location":"modules/00_core/data-dictionary/#32-architectonic-meta-ontology","title":"3.2 Architectonic Meta-Ontology","text":"<ul> <li>Labels: <code>Architectonic</code> (Sub-label: <code>Methodology</code>).</li> <li>Property: <code>architectonic_id</code> (INT, Unique).</li> <li>Hierarchy: Defined by <code>IS_A</code> edges.</li> <li>Purpose: Meta-concepts for methodology and epistemic classification.</li> </ul>"},{"location":"modules/00_core/data-dictionary/#4-technical-constraints","title":"4. Technical Constraints","text":"<ul> <li>IDs: All properties ending in <code>_id</code> must be stored as <code>INT</code> (SQL) and enforced as <code>UNIQUE</code> constraints in Neo4j (Fixtures use slugs for better UX).</li> <li>Strings: All <code>TEXT</code> fields use UTF-8 encoding to support Greek and other non-Latin scripts.</li> </ul>"},{"location":"modules/00_core/fixtures/","title":"IDEA Fixtures: Sandbox Documentation","text":"<p>This document describes the test datasets (fixtures) provided in the IDEA Core Docker container. These examples are designed to demonstrate the framework's ability to model epistemic uncertainty, multimodal interpretations, and complex scene structures. If you want to know more about the annotation process, see how-to-annotate-using-idea.</p>"},{"location":"modules/00_core/fixtures/#1-documentation-assets","title":"1. Documentation Assets","text":"<p>To understand the structural logic of IDEA, we provide both static visual examples and interactive model diagrams.</p> <p> Figure 1: Visual representation of the composition-apple-tomato and composition-billiard-ball test cases.</p> <p>The provided Neo4j Docker setup loads the fixtures directly into the database during startup. Alternatively, you can also find SVGs or JSON exports for Arrows.app here. </p> <ul> <li>\"Apple-Tomato\" Analysis: SVG | JSON</li> <li>\"Apple-Tomato\" Epistemic Layer: SVG | JSON</li> <li>\"Billiard Ball\" Analysis: SVG | JSON</li> <li>\"Billiard Ball\" Epistemic Layer: SVG | JSON</li> <li>Patterns: SVG | JSON</li> <li>Comparisons: SVG | JSON</li> </ul>"},{"location":"modules/00_core/fixtures/#2-design-principles-of-the-fixtures","title":"2. Design Principles of the Fixtures","text":"<ul> <li>Pedagogical Simplification: The images are intentionally AI-generated and only partially annotated. We focus on specific challenges (ambiguity, OCR, AI-vs-Human perception) rather than exhaustive description.</li> <li>Human-Readable IDs: In this sandbox, we use string-based identifiers (e.g., <code>unit-apple-tomato</code>) for easier navigation in the Neo4j Browser. In production, these are mapped to <code>INT</code> keys.</li> <li>Domain Agnosticism: While IDEA is rooted in numismatics, these fixtures use everyday objects to ensure the architectural logic is understood by non-experts.</li> </ul>"},{"location":"modules/00_core/fixtures/#3-case-study-a-the-apple-tomato-epistemic-ambiguity","title":"3. Case Study A: The \"Apple-Tomato\" (Epistemic Ambiguity)","text":"<p>This case demonstrates how IDEA handles material ambiguity where an object cannot be clearly assigned to a single concept.</p>"},{"location":"modules/00_core/fixtures/#data-model-highlights","title":"Data Model Highlights","text":"<ul> <li>Entity Ambiguity: The object is interpreted as both an \"Apple\" and a \"Tomato\".</li> <li>Certainty Scoring: * <code>interpretation-at-tomato</code>: Certainty 0.5 (Primary).</li> <li><code>interpretation-at-apple</code>: Certainty 0.4 (Alternative).</li> <li>Architectonic Linking: Both interpretations are marked as <code>IMPAIRED_BY</code> the architectonic node <code>architectonic-ambiguity</code>.</li> <li>Evidence: The interpretations are supported by conflicting and concurring <code>SourceReference</code> nodes (simulating reference catalogues).</li> </ul>"},{"location":"modules/00_core/fixtures/#4-case-study-b-the-billiard-ball-ai-vs-human-perception","title":"4. Case Study B: The \"Billiard Ball\" (AI vs. Human Perception)","text":"<p>This case illustrates the difference between a \"bottom-up\" AI analysis (geometric decomposition) and a \"top-down\" human analysis (semantic identification), as well as character ambiguity.</p>"},{"location":"modules/00_core/fixtures/#multi-layer-interpretation","title":"Multi-Layer Interpretation","text":"Agent Interpretation Target Identified Concept Certainty Human <code>entity-bb-billiard-ball-sphere</code> <code>concept-billiard-ball-7</code> 1.0 AI <code>entity-bb-billiard-ball-sphere</code> <code>concept-sphere</code> 0.8 AI <code>entity-bb-circle</code> <code>concept-bb-circle</code> 1.0"},{"location":"modules/00_core/fixtures/#reading-ocr-ambiguity","title":"Reading &amp; OCR Ambiguity","text":"<p>The character on the ball is modeled via the <code>Reading</code> node.</p> <ul> <li><code>reading-bb-7</code>: Status \"Primary\", accepted by the human agent.</li> <li><code>reading-bb-l</code>: Status \"Rejected\", stated by the AI but explicitly rejected by the human agent.</li> <li>Both readings are linked to <code>architectonic-ambiguity</code>.</li> </ul>"},{"location":"modules/00_core/fixtures/#5-modeling-logic-the-human-holding-object-pattern","title":"5. Modeling Logic: The \"Human Holding Object\" Pattern","text":"<p>IDEA distinguishes between what is visible and what is represented to maintain a clean ontological structure.</p>"},{"location":"modules/00_core/fixtures/#the-pars-pro-toto-problem-visual-scope","title":"The Pars-pro-Toto Problem &amp; Visual Scope","text":"<p>In both compositions, only a hand is visible. However, we do not model a standalone \"Hand\" entity. Instead:</p> <ul> <li>Entity Identification: We identify the entity as a Human (<code>concept-human</code>).</li> <li>Feature Attribution: We assign a <code>CompositionFeature</code> to the human: <code>feature-at-human-visual-scope</code>.</li> <li>Visual Scope: This is interpreted as <code>concept-detail-hand</code>, a child of <code>concept-human-visual-scope</code>.</li> <li>Reasoning: The <code>reasoning_statement</code> explains that the cropping at the frame edge implies a full human body.</li> </ul>"},{"location":"modules/00_core/fixtures/#handedness-as-a-relation-modifier","title":"Handedness as a Relation Modifier","text":"<p>The \"Hand\" appears a second time in the logic, but as a Modifier of the action:</p> <ul> <li>Relation: The human entity performs the relation <code>relation-at-holding</code>.</li> <li>Modifier: This relation is refined by the modifier <code>modifier-at-using-right-hand</code>.</li> <li>Semantic Link: The modifier is interpreted and linked to the concept <code>concept-using-right-hand</code>.</li> <li>Hierarchy: In the ThING, <code>concept-using-right-hand</code> is a specialization of <code>concept-using-hand</code>.</li> </ul>"},{"location":"modules/00_core/fixtures/#pattern-recognition","title":"Pattern Recognition","text":"<p>Both cases manifest the abstract <code>pattern-human-holding-object</code>. This allows users to query for the general scene structure (Human \u2192 Holding \u2192 Object) regardless of specific attributes or the type of object held.</p>"},{"location":"modules/00_core/fixtures/#6-summary-of-architectonic-nodes","title":"6. Summary of Architectonic Nodes","text":"<p>The fixtures include several <code>Architectonic</code> nodes that define the \"Why\" behind an interpretation:</p> <ul> <li><code>logical-deduction</code>: Used for the \"Presentation\" event interpretation.</li> <li><code>ambiguity</code>: Used for the apple-tomato and character readings.</li> <li><code>compositional-parallel</code>: Used to link the two compositions via a <code>CompositionParallel</code> hub</li> </ul>"},{"location":"modules/00_core/nodes-and-edges/","title":"IDEA Core: Node and Edge Specifications","text":"<p>This document defines the formal structure of the graph.</p> <p>Important notes on performance:  This documentation deals exclusively with the basic structure, not with possible performance optimization, as would be necessary for production. See performance and scaling and roadmap for more information.</p> <p>Important notes on fixtures:  * For better readability, we use string-based IDs in the fixtures. In production, we would use INTs, as we aim to use an SQL database as our sSoT. * The <code>scope</code> property of <code>IDENTIFIED_AS_CONCEPT</code> is not used in the fixtures.</p>"},{"location":"modules/00_core/nodes-and-edges/#general-conventions","title":"General Conventions","text":"<ul> <li>Labels: PascalCase (e.g., <code>CompositionEntity</code>).</li> <li>Properties: lower_snake_case (e.g., <code>reasoning_statement</code>).</li> <li>Edges: UPPER_SNAKE_CASE (e.g., <code>IDENTIFIED_AS_CONCEPT</code>).</li> <li>Directionality: Fixed from the specific/concrete to the abstract/conceptual.</li> <li>Uniqueness: All properties ending in <code>_id</code> are enforced as unique constraints.</li> </ul>"},{"location":"modules/00_core/nodes-and-edges/#1-physical-layer-object-level","title":"1. Physical Layer (Object Level)","text":""},{"location":"modules/00_core/nodes-and-edges/#node-unit","title":"Node: <code>Unit</code>","text":"<p>Description: Represents the physical/virtual object/carrier. Labels: <code>Unit</code></p> Property Type Unique Description <code>unit_id</code> INT Yes Unique identifier for the physical/virtual object/carrier. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_COMPOSITION</code> | <code>Composition</code> | N:M | Links the physical/virtual object/carrier its visual containers/compositions. |</p> <p>Note: Compositions can be linked to multiple units (if the units are definitely identical, serially produced).</p>"},{"location":"modules/00_core/nodes-and-edges/#2-formal-analysis-layer-description-level","title":"2. Formal Analysis Layer (Description Level)","text":""},{"location":"modules/00_core/nodes-and-edges/#node-composition","title":"Node: <code>Composition</code>","text":"<p>Description: A visual container of a unit containing all formal elements. Labels: <code>Composition</code></p> Property Type Unique Description <code>composition_id</code> INT Yes Unique identifier for the composition. <code>chromaticity</code> ENUM No Color properties (e.g., \"Polychromatic\", \"Monochromatic\"). <p>Note: We consider modelling chromaticity as a separate node. See know issues.</p> <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_COMPOSITION_ENTITY</code> | <code>CompositionEntity</code> | 1:N | Identifies a distinct entity in the image. | | <code>HAS_COMPOSITION_CONTEXT</code> | <code>CompositionContext</code> | 1:N | Links to the publication or historical context/meaning. | | <code>HAS_COMPOSITION_GROUP</code> | <code>CompositionGroup</code> | 1:N | Logical grouping of elements. | | <code>HAS_PATTERN</code> | <code>CompositionPattern</code> | 1:N | Reified link to an iconographical pattern. | | <code>HAS_COMPOSITION_COMPARISON</code> | <code>CompositionComparison</code> | 1:N | Links to a comparative analysis with other compositions. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-compositionentity","title":"Node: <code>CompositionEntity</code>","text":"<p>Description: A neutral, formal element identified in the composition (e.g., a figure, an object, decoration). Labels: <code>CompositionEntity</code></p> Property Type Unique Description <code>composition_entity_id</code> INT Yes Unique identifier for the formal entity. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_COMPOSITION_FEATURE</code> | <code>CompositionFeature</code> | 1:N | Assigns an attribute or state to this entity. | | <code>HAS_COMPOSITION_RELATION</code> | <code>CompositionRelation</code> | 1:N | Starts a directed action/relation from this entity. | | <code>IS_PART_OF_COMPOSITION_GROUP</code> | <code>CompositionGroup</code> | N:M | (Optional) Assigns the entity to a group/container. | | <code>HAS_INTERPRETATION</code> | <code>Interpretation</code> | 1:N | Links to the epistemic identification of the entity. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-compositionfeature","title":"Node: <code>CompositionFeature</code>","text":"<p>Description: A formal attribute or temporary state belonging to a <code>CompositionEntity</code>. Labels: <code>CompositionFeature</code></p> Property Type Unique Description <code>composition_feature_id</code> INT Yes Unique identifier for the feature. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_INTERPRETATION</code> | <code>Interpretation</code> | 1:N | Links to the epistemic identification of the feature. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-compositionrelation","title":"Node: <code>CompositionRelation</code>","text":"<p>Description: An atomic action or relationship between two entities. Labels: <code>CompositionRelation</code></p> Property Type Unique Description <code>composition_relation_id</code> INT Yes Unique identifier for the relation. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_COMPOSITION_RELATION_OBJECT</code> | <code>CompositionEntity</code> | N:1 | Defines the target entity (object) of the relation. | | <code>HAS_COMPOSITION_MODIFIER</code> | <code>CompositionModifier</code> | 1:N | Adds specific details (e.g., handedness) to the relation. | | <code>HAS_COMPOSITION_EVENT</code> | <code>CompositionEvent</code> | 1:N | Groups the atomic relation into a macro-event. | | <code>HAS_INTERPRETATION</code> | <code>Interpretation</code> | 1:N | Links to the epistemic identification of the action. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-compositionmodifier","title":"Node: <code>CompositionModifier</code>","text":"<p>Description: Describes the specific execution of a <code>CompositionRelation</code>. Labels: <code>CompositionModifier</code></p> Property Type Unique Description <code>composition_modifier_id</code> INT Yes Unique identifier for the modifier. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_INTERPRETATION</code> | <code>Interpretation</code> | 1:N | Links to the epistemic identification of the modifier. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-compositionevent","title":"Node: <code>CompositionEvent</code>","text":"<p>Description: Represents a macro-level action consisting of (multiple) relations. Labels: <code>CompositionEvent</code></p> Property Type Unique Description <code>composition_event_id</code> INT Yes Unique identifier for the event. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_INTERPRETATION</code> | <code>Interpretation</code> | 1:N | Links to the epistemic identification of the event. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-compositiongroup","title":"Node: <code>CompositionGroup</code>","text":"<p>Description: A logical container or spatial region within a composition. Labels: <code>CompositionGroup</code></p> Property Type Unique Description <code>composition_group_id</code> INT Yes Unique identifier for the group. <code>group_function</code> ENUM No Purpose of the group (e.g., \"LogicalUnit\", \"TextContainer\"). <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_READING</code> | <code>Reading</code> | 1:N | Links to the epistemic interpretation of text in this group. |</p>"},{"location":"modules/00_core/nodes-and-edges/#3-epistemic-layer-interpretation-level","title":"3. Epistemic Layer (Interpretation Level)","text":""},{"location":"modules/00_core/nodes-and-edges/#node-interpretation","title":"Node: <code>Interpretation</code>","text":"<p>Description: The central node for semantic assignment and uncertainty modeling. Labels: <code>Interpretation</code> (Sub-labels: <code>EntityInterpretation</code>, <code>FeatureInterpretation</code>, <code>RelationInterpretation</code>, <code>ModifierInterpretation</code>, <code>EventInterpretation</code>, <code>ContextInterpretation</code>)</p> Property Type Unique Description <code>interpretation_id</code> INT Yes Unique identifier for the interpretation. <code>certainty</code> FLOAT No Confidence value (0.0 to 1.0). <code>status</code> ENUM No Assignment status: \"Primary\", \"Alternative\", \"Rejected\", \"Outdated\". <code>reasoning_statement</code> TEXT No Expert justification for this specific interpretation. <code>timestamp</code> STRING No Date of the interpretation. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>IDENTIFIED_AS_CONCEPT</code> | <code>Concept</code> | 1:N | Semantic link to ThING. Requires <code>scope</code> if N &gt; 1. | | <code>STATED_BY</code> | <code>Agent</code> | N:1 | The Agent who created the interpretation. | | <code>REJECTED_BY</code> / <code>ACCEPTED_BY</code> | <code>Agent</code> | N:M | Validation by one or more agents. | | <code>SUPPORTED_BY</code> | <code>Architectonic</code> | N:M | Methodological grounding (e.g., logical deduction). | | <code>IMPAIRED_BY</code> | <code>Architectonic</code> | N:M | Weakening factors (e.g., ambiguity). | | <code>HAS_SOURCE_REFERENCE</code> | <code>SourceReference</code> | 1:N | Links to external evidence (reference images, literature). | | <code>RECOGNIZED_PATTERN</code> | <code>Pattern</code> | N:1 | Links an interpretation to a generic Pattern definition (only for CompositionsPatterns). | | <code>DEPENDS_ON</code> | <code>Interpretation</code> | 1:N | Logical dependency on another interpretation. |</p> <p>Edge Properties for <code>IDENTIFIED_AS_CONCEPT</code>: (if N &gt; 1)</p> <ul> <li><code>scope</code>: ENUM (\"VisualAppearance\", \"ActualMeaning\", \"FunctionalMeaning\")</li> </ul> <p>Edge Properties for <code>ACCEPTED_BY</code> / <code>REJECTED_BY</code>: (if Interpretation timestamp and Edge timestamp are not equal)</p> <ul> <li><code>timestamp</code>: STRING (if different from interpretation timestamp)</li> </ul>"},{"location":"modules/00_core/nodes-and-edges/#node-reading","title":"Node: <code>Reading</code>","text":"<p>Description: The interpretation of signs/letters. Labels: <code>Reading</code></p> Property Type Unique Description <code>reading_id</code> INT Yes Unique identifier. <code>read_string</code> STRING No The transcribed content. <code>certainty</code> FLOAT No Confidence in the reading. <code>lang</code> STRING No Language code (e.g., \"EN\", \"LAT\"). <code>status</code> ENUM No \"Primary\", \"Alternative\", \"Rejected\", \"oOtdated\". <code>timestamp</code> STRING No Date of entry. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>STATED_BY</code> | <code>Agent</code> | N:1 | The Agent who created the interpretation. | | <code>REJECTED_BY</code> / <code>ACCEPTED_BY</code> | <code>Agent</code> | N:M | Validation by one or more agents. | | <code>IMPAIRED_BY</code> | <code>Architectonic</code> | N:M | Factors like wear or fragmentation. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-sourcereference","title":"Node: <code>SourceReference</code>","text":"<p>Description: A specific evidentiary statement linking an interpretation to a source. Labels: <code>SourceReference</code></p> Property Type Unique Description <code>source_reference_id</code> INT Yes Unique identifier. <code>reference</code> STRING No Specific locator (e.g., page number, image-ID). <code>refrence_statement</code> TEXT No Description of the evidence found in the source. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_SOURCE</code> | <code>Source</code> | N:1 | Links to the container source. | | <code>HAS_EVIDENTIARY_RELATIONSHIP</code>| <code>Architectonic</code>| N:1 | Nature of evidence (e.g., \"concurring\", \"conflicting\"). |</p>"},{"location":"modules/00_core/nodes-and-edges/#4-ontological-layer-thing-patterns","title":"4. Ontological Layer (ThING &amp; Patterns)","text":""},{"location":"modules/00_core/nodes-and-edges/#node-concept","title":"Node: <code>Concept</code>","text":"<p>Description: Semantic lemma in the Tree of Concepts. Labels: <code>Concept</code> (Sub-labels: <code>Entity</code>, <code>Feature</code>, <code>Relation</code>, <code>Modifier</code>, <code>Event</code>, <code>Context</code>)</p> Property Type Unique Description <code>concept_id</code> INT Yes Semantic URI or ID. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>IS_A</code> | <code>Concept</code> | N:M | Hierarchical parent-child relationship (Strictly Acyclic). |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-pattern","title":"Node: <code>Pattern</code>","text":"<p>Description: Abstract iconographical pattern defining a scene structure. Labels: <code>Pattern</code></p> Property Type Unique Description <code>pattern_id</code> INT Yes Unique identifier for the pattern. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_PATTERN_ENTITY</code> | <code>PatternEntity</code> | 1:N | Defines an abstract actor in the pattern. |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-patternentity","title":"Node: <code>PatternEntity</code>","text":"<p>Description: Abstract placeholder for an entity within a pattern. Labels: <code>PatternEntity</code></p> Property Type Unique Description <code>pattern_entity_id</code> INT Yes Unique identifier. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_CONCEPT</code> | <code>Concept</code> | N:M | The required semantic type for this actor. | | <code>HAS_PATTERN_RELATION</code> | <code>PatternRelation</code> | 1:N | Defines actions expected from this actor in the pattern. |</p> <p>Edge Properties for <code>HAS_CONCEPT</code>: (if N &gt; 1)</p> <ul> <li><code>scope</code>: ENUM (\"VisualAppearance\", \"ActualMeaning\", \"FunctionalMeaning\")</li> </ul>"},{"location":"modules/00_core/nodes-and-edges/#node-patternrelation","title":"Node: <code>PatternRelation</code>","text":"<p>Description: Abstract placeholder for an action within a pattern. Labels: <code>PatternRelation</code></p> Property Type Unique Description <code>pattern_relation_id</code> INT Yes Unique identifier. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>HAS_CONCEPT</code> | <code>Concept</code> | N:M | The required semantic type for the action. | | <code>HAS_PATTERN_RELATION_OBJECT</code>| <code>PatternEntity</code> | N:1 | The abstract target of the action. |</p> <p>Edge Properties for <code>HAS_CONCEPT</code>: (if N &gt; 1)</p> <ul> <li><code>scope</code>: ENUM (\"VisualAppearance\", \"ActualMeaning\", \"FunctionalMeaning\")</li> </ul>"},{"location":"modules/00_core/nodes-and-edges/#node-architectonic","title":"Node: <code>Architectonic</code>","text":"<p>Description: Meta-concepts for methodology and epistemic classification. Labels: <code>Architectonic</code> (Sub-label: <code>Methodology</code>)</p> Property Type Unique Description <code>architectonic_id</code> INT Yes Unique identifier. <p>Outgoing Edges: | Type | Target Node | Cardinality | Description | | :--- | :--- | :--- | :--- | | <code>IS_A</code> | <code>Architectonic</code> | N:M | Hierarchical relationship (Strictly Acyclic). |</p>"},{"location":"modules/00_core/nodes-and-edges/#node-agent","title":"Node: <code>Agent</code>","text":"<p>Description: Entities (Human or AI) responsible for statements and validations. Labels: <code>Agent</code> (Sub-labels: <code>HumanAgent</code>, <code>AIAgent</code>)</p> Property Type Unique Description <code>agent_id</code> INT Yes Unique identifier for the agent."},{"location":"modules/00_core/nodes-and-edges/#node-source","title":"Node: <code>Source</code>","text":"<p>Description: Bibliographic or archival container (e.g., a book or database). Labels: <code>Source</code></p> Property Type Unique Description <code>source_id</code> INT Yes Unique identifier."},{"location":"modules/00_core/queries/","title":"IDEA: Example Queries","text":"<p>This document provides example Cypher queries to demonstrate the investigative potential of the IDEA framework. These queries are designed to run against the IDEA Core (as defined in <code>99_fixtures.cypher</code>), utilizing standard graph traversals without performance-optimized materialized paths.</p>"},{"location":"modules/00_core/queries/#1-ontology-overview-recursive-hierarchy","title":"1. Ontology Overview (Recursive Hierarchy)","text":"<p>Scenario: Show all concepts descending from concept-object as paths.</p> <p><pre><code>MATCH path = (child:Concept)-[:IS_A*]-&gt;(parent:Concept {concept_id: 'concept-object'})\nRETURN path\n</code></pre> Expected Output: * (:Concept:Fixture:Entity {concept_id: \"concept-sports-equipment\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-object\"}) * (:Concept:Fixture:Entity {concept_id: \"concept-billiard-ball\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-sports-equipment\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-object\"}) * (:Concept:Fixture:Entity {concept_id: \"concept-billiard-ball-7\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-billiard-ball\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-sports-equipment\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-object\"}) * (:Concept:Fixture:Entity {concept_id: \"concept-fruit\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-object\"}) * (:Concept:Fixture:Entity {concept_id: \"concept-apple\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-fruit\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-object\"}) * (:Concept:Fixture:Entity {concept_id: \"concept-tomato\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-fruit\"})-[:IS_A]-&gt;(:Concept:Fixture:Entity {concept_id: \"concept-object\"})</p> <p>NOTE: These nodes represent the strictly acyclic hierarchy of the model. Concept related metadata can be added via ontology module. They can be further enriched with domain-specific modules (e.g., Numismatics) to provide detailed descriptions of ancient iconography.</p>"},{"location":"modules/00_core/queries/#2-semantic-context-human-holding-fruit","title":"2. Semantic Context: \"Human holding Fruit\"","text":"<p>Scenario: Find compositions where a human (Entity) is holding (Relation) as fruit (Entity), not just keywords.</p> <p><pre><code>MATCH (u:Unit)-[:HAS_COMPOSITION]-&gt;(comp:Composition)\n\nMATCH (comp)-[:HAS_COMPOSITION_ENTITY]-&gt;(ce_human:CompositionEntity)\nMATCH (ce_human)-[:HAS_INTERPRETATION]-&gt;(:Interpretation)-[:IDENTIFIED_AS_CONCEPT]-&gt;(:Concept {concept_id: 'concept-human'})\n\nMATCH (ce_human)-[:HAS_COMPOSITION_RELATION]-&gt;(rel:CompositionRelation)\nMATCH (rel)-[:HAS_INTERPRETATION]-&gt;(:Interpretation)-[:IDENTIFIED_AS_CONCEPT]-&gt;(:Concept {concept_id: 'concept-holding'})\n\nMATCH (rel)-[:HAS_COMPOSITION_RELATION_OBJECT]-&gt;(ce_fruit:CompositionEntity)\nMATCH (ce_fruit)-[:HAS_INTERPRETATION]-&gt;(:Interpretation)-[:IDENTIFIED_AS_CONCEPT]-&gt;(c_fruit:Concept)\nMATCH (c_fruit)-[:IS_A*0..]-&gt;(:Concept {concept_id: 'concept-fruit'})\n\nRETURN DISTINCT comp.composition_id\n</code></pre> Expected Output: * composition-apple-tomato</p>"},{"location":"modules/00_core/queries/#3-high-certainty-fact-extraction","title":"3. High-Certainty Fact Extraction","text":"<p>Scenario: Retrieve only the \"Gold Standard\" identifications of entities where the certainty is high and the status is primary.</p> <pre><code>MATCH (u:Unit)-[:HAS_COMPOSITION]-&gt;(c:Composition)\nMATCH (c)-[:HAS_COMPOSITION_ENTITY]-&gt;(ce:CompositionEntity)\nMATCH (ce)-[:HAS_INTERPRETATION]-&gt;(i:Interpretation)\nMATCH (i)-[:IDENTIFIED_AS_CONCEPT]-&gt;(con:Concept)\nWHERE i.status = 'Primary' \n  AND i.certainty &gt; 0.8\nRETURN ce.composition_entity_id, con.concept_id, i.certainty\n</code></pre> <p>Expected Output: * entity-at-human, concept-human, 1.0 * entity-bb-billiard-ball-sphere, concept-billiard-ball-7, 1.0</p>"},{"location":"modules/00_core/queries/#4-human-in-the-loop-rejected-interpretations","title":"4. Human-in-the-Loop: Rejected Interpretations","text":"<p>Scenario: Identify entity interpretations that were proposed (e.g., by an AI) but explicitly rejected by a human expert. This is essential for identifying AI bias or outdated scholarly opinions</p> <pre><code>MATCH (ce:CompositionEntity)-[:HAS_INTERPRETATION]-&gt;(i:Interpretation)\nMATCH (i)-[:REJECTED_BY]-&gt;(a:HumanAgent)\nMATCH (i)-[:IDENTIFIED_AS_CONCEPT]-&gt;(con:Concept)\nRETURN ce.composition_entity_id, con.concept_id, i.reasoning_statement\n</code></pre> <p>Expected Output: * entity-bb-glyph, concept-letter-l, \"Commen Scheme, but ambiguous\"</p>"},{"location":"modules/00_core/queries/#5-conflict-analysis-interpretations-vs-sources","title":"5. Conflict Analysis: Interpretations vs. Sources","text":"<p>Scenario: Find cases where an expert's interpretation is in direct conflict with the cited reference material. This is important to understand the low certainty or to check the references.</p> <p><pre><code>MATCH (i:Interpretation)-[:HAS_SOURCE_REFERENCE]-&gt;(sr:SourceReference)\nMATCH (sr)-[:HAS_EVIDENTIARY_RELATIONSHIP]-&gt;(arch:Architectonic {architectonic_id: 'architectonic-conflicting'})\nMATCH (sr)-[:HAS_SOURCE]-&gt;(s:Source)\nMATCH (i)-[:STATED_BY]-&gt;(agent:Agent)\nRETURN i.interpretation_id, agent.agent_id, sr.reference, sr.refrence_statement, s.source_id\n</code></pre> Expected Output: * interpretation-at-apple, agent-human, img-at-apple-conflicting, \"apple reference image shows stem\", source-at-reference-catalogue</p>"},{"location":"modules/00_core/queries/#6-pattern-based-rapid-access","title":"6. Pattern-Based Rapid Access","text":"<p>Scenario: Quickly identify all Compositions that match a standardized iconographical scene, such as \"Human holding object\". This is faster than going into the formal analysis.</p> <pre><code>MATCH (u:Unit)-[:HAS_COMPOSITION]-&gt;(c:Composition)\nMATCH (c)-[:HAS_PATTERN]-&gt;(cp:CompositionPattern)\nMATCH (cp)-[:HAS_RECOGNITION]-&gt;(i:Interpretation)\nMATCH (i)-[:RECOGNIZED_PATTERN]-&gt;(p:Pattern {pattern_id: 'pattern-human-holding-object'})\nRETURN u.unit_id, c.composition_id, i.certainty\n</code></pre> <p>Expected Output: * unit-apple-tomato, composition-apple-tomato, 1.0 * unit-billiard-ball, composition-billiard-ball, 1.0</p>"},{"location":"modules/05_ontology/","title":"IDEA Ontology","text":"<ul> <li>Status: Planned / Concept Phase.</li> <li>Scope: Extended Core</li> <li>Objective: Adding the \"semantic flesh\" to the Ontological Layer to fully represent the ThING (Thesaurus Iconographicus Nummorum Graecorum).</li> <li>Planned Features:</li> <li>Multi-language Support: Labels and definitions in EN, DE, LAT, GRC.</li> <li>LOD-Mapping: Explicit edges to external authorities (e.g., Getty AAT, Wikidata, Nomisma.org).</li> <li>Semantic Properties: Detailed conceptual descriptions and scope notes.</li> </ul>"},{"location":"modules/10_numismatics/","title":"IDEA Numismatics","text":"<ul> <li>Status: Planned / Concept Phase.</li> <li>Scope: Domain-specific</li> <li>Objective: The first domain-specific implementation of IDEA, tailored for ancient coinage.</li> <li>Planned Features:</li> <li>Specialized Labels: Extending <code>Unit</code> with <code>Coin</code> and <code>Composition</code> with <code>CoinObverse</code> or <code>CoinReverse</code>.</li> <li>Numismatic Metadata: Integrating physical properties specific to coins (e.g., weight, diameter, die-axis).</li> </ul>"}]}